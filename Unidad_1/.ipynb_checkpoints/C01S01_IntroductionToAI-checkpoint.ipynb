{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Intelligence\n",
    "\n",
    "In this section, you will be introduced to the fundamentals of Artificial Intelligence (AI), which are the foundations of various fields of AI. You will also come across different algorithms, including MinMax and A*, through simple coding exercises using the Python programming language. You will also be implementing your first AI through a simple tic-tac-toe game where you will be teaching the program how to win against a human player.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Before discussing the different AI techniques and algorithms, we will look at the fundamentals of AI and machine learning and go through a few basic definitions. Real-world examples will be used to present the basic concepts of AI in an easy-to-digest way.\n",
    "\n",
    "AI attempts to replicate human intelligence using hardware and software solutions. It is based on reverse engineering. For example, artificial neural networks are modeled after the way the human brain works. Beyond neural networks, there are many other models in neuroscience that can be used to solve real-world problems using AI. Companies that are known to be using AI in their fields include Google, with Google Translate, Apple, with Face ID, Amazon, with its Alexa products, and even Uber and Tesla, who are still working on building self-driving cars.\n",
    "\n",
    "On the other hand, machine learning is a term that is often confused with AI. It originates from the 1950s and was first defined by Arthur Lee Samuel in 1959.\n",
    "\n",
    "In his book called Machine Learning, Tom Mitchell proposed a simple definition of it: *\"The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with experience.\"*\n",
    "\n",
    "We can understand this as machine learning being the field where the goal is to build a computer program capable of learning patterns from data and improve its learning ability with more data.\n",
    "\n",
    "He also proposed a more formal definition, which is that a computer program is said to learn from experience, **E**, with respect to a task, **T**, and a performance measure, **P**, if its performance on **T**, as measured by **P**, improves with experience, **E**. This can be translated as what a computer program requires in order for it to be learning. We can see **E** (the experience) as the data that needs to be fed to the machine, **T**, as the type of decision that the machine needs to perform, and **P** as the measure of its performance.\n",
    "\n",
    "From these two definitions, we can conclude that machine learning is one way to achieve AI. However, you can have AI without machine learning. For instance, if you hardcode rules and decision trees, or you apply search techniques, you can create an AI agent, even though your approach has little to do with machine learning.\n",
    "\n",
    "AI and machine learning have helped the scientific community harness the explosion of big data with more and more data being created every second. With AI and machine learning, scientists can extract information that human eyes cannot process fast enough on these huge datasets.\n",
    "\n",
    "Now that we have been introduced to AI and machine learning, let's focus on AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Does AI Solve Problems?\n",
    "\n",
    "AI automates human intelligence based on the way a human brain processes information.\n",
    "\n",
    "Whenever we solve a problem or interact with people, we go through a process. By doing this, we limit the scope of a problem or interaction. This process can often be modeled and automated in AI.\n",
    "\n",
    "AI makes computers appear to think like humans.\n",
    "\n",
    "Sometimes, it feels like the AI knows what we need. Just think about the personalized coupons you receive after shopping online. AI knows which product we will most likely be purchasing. Machines are able to learn your preferences through the implementation of different techniques and models, which we will look at later in this book.\n",
    "\n",
    "AI is performed by computers that are executing low-level instructions.\n",
    "\n",
    "Even though a solution may appear to be intelligent, we write code, just like with any other software solution in AI. Even if we are simulating neurons, simple machine code and computer hardware executes the thinking process.\n",
    "\n",
    "Most AI applications have one primary objective. When we interact with an AI application, it seems human-like because it can restrict a problem domain to a primary objective. Therefore, the process whereby the AI reaches the objective can be broken down into smaller and simpler low-level instructions.\n",
    "\n",
    "AI may stimulate human senses and thinking processes for specialized fields.\n",
    "\n",
    "You must be able to simulate human senses and thoughts, and sometimes trick AI into believing that we are interacting with another human. In some special cases, we can even enhance our own senses.\n",
    "\n",
    "Similarly, when we interact with a chatbot, for instance, we expect the bot to understand us. We expect the chatbot or even a voice recognition system to provide a computer-human interface that fulfills our expectations. In order to meet these expectations, computers need to emulate human thought processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity of Disciplines in AI\n",
    "\n",
    "A self-driving car that cannot sense other cars driving on the same highway would be incredibly dangerous. The AI agent needs to process and sense what is around it in order to drive the car. However, this is not enough since, without understanding the physics of moving objects, driving the car in a normal environment would be an almost impossible, not to mention deadly, task.\n",
    "\n",
    "In order to create a usable AI solution, different disciplines are involved, such as the following:\n",
    "\n",
    "  * **Robotics**: To move objects in space\n",
    "  * **Algorithm theory**: To construct efficient algorithms\n",
    "  * **Statistics**: To derive useful results, predict the future, and analyze the past\n",
    "  * **Psychology**: To model how the human brain works\n",
    "  * **Software engineering**: To create maintainable solutions that endure the test of time\n",
    "  * **Computer science** or **computer programming**: To implement our software solutions in practice\n",
    "  * **Mathematics**: To perform complex mathematical operations\n",
    "  * **Control theory**: To create feed-forward and feedback systems\n",
    "  * **Information theory**: To represent, encode, decode, and compress information\n",
    "  * **Graph theory**: To model and optimize different points in space and to represent hierarchies\n",
    "  * **Physics**: To model the real world\n",
    "  * **Computer graphics** and **image processing**: To display and process images and movies\n",
    "  \n",
    "In this course, we will use a few of these disciplines, including algorithm theory, statistics, computer science, mathematics, and image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields and Applications of AI\n",
    "\n",
    "Now that we have been introduced to AI, let's move on and see its application in real life.\n",
    "\n",
    "### Simulation of Human Behavior\n",
    "\n",
    "Humans have five basic senses that can be divided into visual (seeing), auditory (listening), kinesthetic (moving), olfactory (smelling), and gustatory (tasting). However, for the purposes of understanding how to create intelligent machines, we can separate these disciplines as follows:\n",
    "\n",
    "  * Listening and speaking\n",
    "  * Understanding language\n",
    "  * Remembering things\n",
    "  * Thinking\n",
    "  * Seeing\n",
    "  * Moving\n",
    "  \n",
    "A few of these are out of scope for us because the purpose of this section is to understand the fundamentals. In order to move a robot arm, for instance, we would have to study complex university-level math to understand what's going on, but we will only be sticking to the practical aspects in this course:\n",
    "\n",
    "  * **Listening and speaking**: Using a speech recognition system, AI can collect information from a user. Using speech synthesis, it can turn internal data into understandable sounds. Speech recognition and speech synthesis techniques deal with the recognition and construction of human sounds that are emitted or that humans can understand. For instance, imagine you are on a trip to a country where you don't speak the local language. You can speak into the microphone of your phone, expect it to understand what you say, and then translate it into the other language. The same can happen in reverse with the locals speaking and AI translating the sounds into a language you understand. Speech recognition and speech synthesis make this possible.\n",
    "  * **Understanding language**: We can understand natural language by processing it. This field is called natural language processing, or NLP. When it comes to NLP, we tend to learn languages based on statistical learning by learning the statistical relationship between syllables.\n",
    "  * **Remembering things**: We need to represent things we know about the world. This is where creating knowledge bases and hierarchical representations called ontologies comes into play. Ontologies categorize things and ideas in our world and contain relations between these categories.\n",
    "  * **Thinking**: Our AI system has to be an expert in a certain domain by using an expert system. An expert system can be based on mathematical logic in a deterministic way, as well as in a fuzzy, non-deterministic way. The knowledge base of an expert system is represented using different techniques. As the problem domain grows, we create hierarchical ontologies. We can replicate this structure by modeling the network on the building blocks of the brain. These building blocks are called neurons, and the network itself is called a neural network.\n",
    "  * **Seeing**: We have to interact with the real world through our senses. We have only touched upon auditory senses so far, in regard to speech recognition and synthesis. What if we had to see things? If that was the case, we would have to create computer vision techniques to learn about our environment. After all, recognizing faces is useful, and most humans are experts at that. Computer vision depends on image processing. Although image processing is not directly an AI discipline, it is a required discipline for AI.\n",
    "  * **Moving**: Moving and touching are natural to us humans, but they are very complex tasks for computers. Moving is handled by robotics. This is a very math-heavy topic. Robotics is based on control theory, where you create a feedback loop and control the movement of your object based on the feedback gathered. Control theory has applications in other fields that have absolutely nothing to do with moving objects in space. This is because the feedback loops that are required are similar to those modeled in economics.\n",
    "  \n",
    "### Simulating Intelligence – the Turing Test\n",
    "\n",
    "Alan Turing, inventor of the Turing machine, an abstract concept that's used in algorithm theory, suggested a way to test intelligence. This test is referred to as the Turing test in AI literature.\n",
    "\n",
    "Using a text interface, an interrogator chats to a human and a chatbot. The job of the chatbot is to mislead the interrogator to the extent that they cannot tell whether the computer is human.\n",
    "\n",
    "### What Disciplines Do We Need to Pass the Turing Test?\n",
    "\n",
    "First, we need to understand a spoken language to know what the interrogator is saying. We do this by using **Natural Language Processing (NLP)**. We also must respond to the interrogator in a credible way by learning from previous questions and answers using AI models.\n",
    "\n",
    "We need to be an expert of things that the human mind tends to be interested in. We need to build an expert system of humanity, involving the taxonomy of objects and abstract thoughts in our world, as well as historical events and even emotions.\n",
    "\n",
    "Passing the Turing test is very hard. Current predictions suggest we won't be able to create a system good enough to pass the Turing test until the late 2020s. Pushing this even further, if this is not enough, we can advance to the Total Turing Test, which also includes movement and vision.\n",
    "\n",
    "Next, we will move on and look at the tools and learning models in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Tools and Learning Models\n",
    "\n",
    "In the previous sections, we discovered the fundamentals of AI. One of the core tasks of AI is learning. This is where intelligent agents come into the picture.\n",
    "\n",
    "### Intelligent Agents\n",
    "\n",
    "When solving AI problems, we create an actor in the environment that can gather data from its surroundings and influence its surroundings. This actor is called an **intelligent agent**.\n",
    "\n",
    "An intelligent agent is as follows:\n",
    "\n",
    "  * Is autonomous\n",
    "  * Observes its surroundings through sensors\n",
    "  * Acts in its environment using actuators (which are the components that are responsible for moving and controlling a mechanism)\n",
    "  * Directs its activities toward achieving goals\n",
    "  \n",
    "Agents may also learn and have access to a knowledge base.\n",
    "\n",
    "We can think of an agent as a function that maps perceptions to actions. If the agent has an internal knowledge base, then perceptions, actions, and reactions may alter the knowledge base as well.\n",
    "\n",
    "Actions may be rewarded or punished. Setting up a correct goal and implementing a carrot and stick situation helps the agent learn. If goals are set up correctly, agents have a chance of beating the often more complex human brain. This is because the primary goal of the human brain is survival, regardless of the game we are playing. An agent's primary motive is reaching the goal itself. Therefore, intelligent agents do not get embarrassed when making a random move without any knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Role of Python in AI\n",
    "\n",
    "In order to put basic AI concepts into practice, we need a programming language that supports AI. In this course, we have chosen Python. There are a few reasons why Python is such a good choice for AI:\n",
    "\n",
    "  * **Convenience and Compatibility**: Python is a high-level programming language. This means that you don't have to worry about memory allocation, pointers, or machine code in general. You can write code in a convenient fashion and rely on Python's robustness. Python is also cross-platform compatible.\n",
    "  * **Popularity**: The strong emphasis on developer experience makes Python a very popular choice among software developers. In fact, according to a 2018 developer survey by [https://www.hackerrank.com](https://www.hackerrank.com), across all ages, Python ranks as the number one preferred language of software developers. This is because Python is easily readable and simple. Therefore, Python is great for rapid application development.\n",
    "  * **Efficiency**: Despite being an interpreted language, Python is comparable to other languages that are used in data science, such as R. Its main advantage is memory efficiency, since Python can handle large, in-memory databases.\n",
    "    > Python is a multi-purpose language. It can be used to create desktop applications, database applications, mobile applications, and games. The network programming features of Python are also worth mentioning. Furthermore, Python is an excellent prototyping tool.\n",
    "    \n",
    "### Why Is Python Dominant in Machine Learning, Data Science, and AI?\n",
    "\n",
    "To understand the dominant nature of Python in machine learning, data science, and AI, we have to compare Python to other languages that are also used in these fields.\n",
    "\n",
    "Compared to R, which is a programming language built for statisticians, Python is much more versatile and easy as it allows programmers to build a diverse range of applications, from games to AI applications.\n",
    "\n",
    "Compared to Java and C++, writing programs in Python is significantly faster. Python also provides a high degree of flexibility.\n",
    "\n",
    "There are some languages that are similar in nature when it comes to flexibility and convenience: Ruby and JavaScript. Python has an advantage over these languages because of the AI ecosystem that's available for Python. In any field, open source, third-party library support vastly determines the success of that language. Python's third-party AI library support is excellent.\n",
    "\n",
    "### Anaconda in Python\n",
    "\n",
    "You can install Anaconda for using in this course. Anaconda comes with packages, IDEs, data visualization libraries, and high-performance tools for parallel computing in one place. Anaconda hides configuration problems and the complexity of maintaining a stack for data science, machine learning, and AI. This feature is especially useful in Windows, where version mismatches and configuration problems tend to arise the most.\n",
    "\n",
    "Anaconda comes with Jupyter Notebook, where you can write code and comments in a documentation style. When you experiment with AI features, the flow of your ideas resembles an interactive tutorial where you run each step of your code.\n",
    "  \n",
    "  > **IDE** stands for **Integrated Development Environment**. While a text editor provides some functionalities to highlight and format code, an IDE goes beyond the features of text editors by providing tools to automatically refactor, test, debug, package, run, and deploy code.\n",
    "  \n",
    "### Python Libraries for AI\n",
    "\n",
    "The list of libraries presented here is not complete as there are more than 700 available in Anaconda. However, these specific ones will get you off to a good start because they will give you a good foundation to be able to implement the fundamental AI algorithms in Python:\n",
    "\n",
    "  * **NumPy**: NumPy is a computing library for Python. As Python does not come with a built-in array data structure, we have to use a library to model vectors and matrices efficiently. In data science, we need these data structures to perform simple mathematical operations. We will use NumPy extensively.\n",
    "  * **SciPy**: SciPy is an advanced library containing algorithms that are used for data science. It is a great complementary library to NumPy because it gives you all the advanced algorithms you need, whether it be a linear algebra algorithm, image processing tool, or a matrix operation.\n",
    "  * **pandas**: pandas provides fast, flexible, and expressive data structures, such as one-dimensional series and two-dimensional DataFrames. It efficiently loads, formats, and handles complex tables of different types.\n",
    "  * **scikit-learn**: scikit-learn is Python's main machine learning library. It is based on the NumPy and SciPy libraries. scikit-learn provides you with the functionality required to perform both classification and regression, data preprocessing, as well as supervised and unsupervised learning.\n",
    "  * **NLTK**: We will not deal with NLP in this book, but NLTK is still worth mentioning because this library is the main natural language toolkit of Python. You can perform classification, tokenization, stemming, tagging, parsing, semantic reasoning, and many other operations using this library.\n",
    "  * **TensorFlow**: TensorFlow is Google's neural network library, and it is perfect for implementing deep learning AI. The flexible core of TensorFlow can be used to solve a vast variety of numerical computation problems. Some real-world applications of TensorFlow include Google voice recognition and object identification.\n",
    "\n",
    "### A Brief Introduction to the NumPy Library\n",
    "\n",
    "The NumPy library will play a major role in this book, so it is worth exploring it further.\n",
    "\n",
    "After launching your Jupyter Notebook, you can simply import `numpy` as follows:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "Once `numpy` has been imported, you can access it using its alias, `np`. NumPy contains the efficient implementation of some data structures, such as vectors and matrices.\n",
    "\n",
    "Let's see how we can define vectors and matrices:\n",
    "\n",
    "```Python\n",
    "np.array([1,3,5,7])\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "array([1, 3, 5, 7])\n",
    "```\n",
    "\n",
    "We can declare a matrix using the following syntax:\n",
    "\n",
    "```Python\n",
    "A = np.mat([[1,2],[3,3]])\n",
    "A\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "matrix([[1, 2],\n",
    "        [3, 3]])\n",
    "```\n",
    "\n",
    "The `array` method creates an array data structure, while `.mat` creates a matrix.\n",
    "\n",
    "We can perform many operations with matrices. These include addition, subtraction, and multiplication. Let's have a look at these operations here:\n",
    "\n",
    "Addition in matrices:\n",
    "\n",
    "```Python\n",
    "A + A\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "matrix([[2, 4],\n",
    "        [6, 6]])\n",
    "```\n",
    "\n",
    "Subtraction in matrices:\n",
    "\n",
    "```Python\n",
    "A - A\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "matrix([[0, 0],\n",
    "        [0, 0]])\n",
    "```\n",
    "\n",
    "Multiplication in matrices:\n",
    "\n",
    "```\n",
    "A * A\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "matrix([[ 7,  8],\n",
    "        [12, 15]])\n",
    "```\n",
    "\n",
    "Matrix addition and subtraction work cell by cell.\n",
    "\n",
    "Matrix multiplication works according to linear algebra rules. To calculate matrix multiplication manually, you have to align the two matrices, as follows:\n",
    "\n",
    "![Figure 1.1](img/fig1_01.jpg)\n",
    "\n",
    "To get the $(i,j)th$ element of the matrix, you compute the dot (scalar) product on the $ith$ row of the matrix with the $jth$ column. The scalar product of two vectors is the sum of the product of their corresponding coordinates.\n",
    "\n",
    "Another frequent matrix operation is the determinant of the matrix. The determinant is a number associated with square matrices. Calculating the determinant using NumPy's `linalg` function (linear algebra algorithms) can be seen in the following line of code:\n",
    "\n",
    "```Python\n",
    "np.linalg.det( A )\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "-3.0000000000000004\n",
    "```\n",
    "\n",
    "Technically, the determinant can be calculated as $1*3 – 2*3 = -3$. Notice that NumPy calculates the determinant using floating-point arithmetic, so the accuracy of the result is not perfect. The error is due to the way floating points are represented in most programming languages.\n",
    "\n",
    "We can also transpose a matrix, as shown in the following line of code:\n",
    "\n",
    "```Python\n",
    "np.matrix.transpose(A)\n",
    "```\n",
    "\n",
    "The expected output is this:\n",
    "\n",
    "```\n",
    "matrix([[1, 3],\n",
    "        [2, 3]])\n",
    "```\n",
    "\n",
    "When calculating the transpose of a matrix, we flip its values over its main diagonal.\n",
    "\n",
    "**Go to Exercise 1.01**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Game AI\n",
    "\n",
    "An AI game player is nothing but an intelligent agent with a clear goal: to win the game and defeat all the other players. AI experiments have achieved surprising results when it comes to games. Today, no human can defeat an AI in the game of chess.\n",
    "\n",
    "The game Go was the last game where human players could consistently defeat a computer player. However, in 2017, Google's game-playing AI called AlphaGo defeated the world number 1 ranked Go player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligent Agents in Games\n",
    "\n",
    "An intelligent agent plays according to the rules of the game. The agent can sense the current state of the game through its sensors and can evaluate the potential steps. Once the agent finds the best possible step, it performs the action using its actuators. The agent finds the best possible action to reach the goal based on the information it has. Actions are either rewarded or punished. The carrot and stick are excellent examples of rewards and punishment. Imagine a donkey in front of your cart. You put a carrot in front of the eyes of the donkey, so the animal starts walking toward it. As soon as the donkey stops, the rider may apply punishment with a stick. This is not a human way of moving, but rewards and punishment control living organisms to some extent. The same happens to humans at school, at work, and in everyday life as well. Instead of carrots and sticks, we have income and legal punishment to shape our behavior.\n",
    "\n",
    "In most games, a good sequence of actions results in a reward. When a human player feels rewarded, that makes the human feel happy. Humans tend to act in a way that maximizes their happiness. Intelligent agents, on the other hand, are only interested in their goal, which is to maximize their reward and minimize the punishment that's affecting their performance score.\n",
    "\n",
    "When modeling games, we must determine their state space. An action causes a state transition. When we explore the consequences of all possible actions, we get a decision tree. This tree goes deeper as we start exploring the possible future actions of all players until the game ends.\n",
    "\n",
    "The strength of AI is the execution of millions of possible steps each second. Therefore, game AI often boils down to a search exercise. When exploring all of the possible sequences of moves in a game, we get the state tree of a game.\n",
    "\n",
    "Consider a chess AI. What is the problem with evaluating all possible moves by building a state tree consisting of all of the possible sequences of moves?\n",
    "\n",
    "Chess is an EXPTIME game complexity-wise. The number of possible moves explodes combinatorically.\n",
    "\n",
    "White starts with $20$ possible moves: the eight pawns may move either one or two steps, and the two knights may move either up-up-left, or up-up-right. Then, black can make any of these $20$ moves. There are already $20*20 = 400$ possible combinations after just one move per player.\n",
    "\n",
    "After the second move, we get 8,902 possible board constellations, and this number just keeps on growing. Just take seven moves, and you have to search through 10,921,506 possible constellations.\n",
    "\n",
    "The average length of a chess game is approximately 40 moves. Some exceptional games take more than 200 moves to finish.\n",
    "\n",
    "As a consequence, the computer player simply does not have time to explore the whole state space. Therefore, the search activity has to be guided with proper rewards, punishment, and simplifications of the rules.\n",
    "\n",
    "### Breadth First Search and Depth First Search\n",
    "\n",
    "Creating a game AI is often a search exercise. Therefore, we need to be familiar with the two primary search techniques:\n",
    "\n",
    "  * Breadth First Search (BFS)\n",
    "  * Depth First Search (DFS)\n",
    "  \n",
    "These search techniques are applied on a directed rooted tree.\n",
    "\n",
    "A tree is a data structure that has **nodes**, and **edges** connecting these nodes in such a way that any two nodes of the tree are connected by exactly one path. Have a look at the following figure:\n",
    "\n",
    "![Figure 1.3](img/fig1_03.jpg)\n",
    "\n",
    "When the tree is rooted, there is a special node in the tree called the **root**, which is where we begin our traversal. A directed tree is a tree where the edges may only be traversed in one direction. Nodes may be internal nodes or leaves. **Internal nodes** have at least one edge, through which we can leave the node. A **leaf** has no edges pointing out from the node.\n",
    "\n",
    "In AI search, the root of the tree is the starting state. We traverse from this state by generating the successor nodes of the search tree. Search techniques differ, depending on the order in which we visit these successor nodes.\n",
    "\n",
    "#### Breadth First Search (BFS)\n",
    "\n",
    "BFS is a search technique that, starting from the root node (node 1), will start exploring the closest node on the same depth (or level) before moving to the next depth:\n",
    "\n",
    "![Figure 1.4](img/fig1_04.jpg)\n",
    "\n",
    "In the preceding figure, you can see the search order of the BFS technique. Starting from the root node $(1)$, BFS will go to the next level and explore the closest node $(2)$ before looking at the other nodes on the same level ($3$ and $4$). Then, it will move to the next level and explore $5$ and $6$ as they are close to each other before going back through to node $3$, finishing on the last node $(7)$, and so on.\n",
    "\n",
    "#### Depth First Search (DFS)\n",
    "\n",
    "DFS is a search technique that, starting from the root node (node $1$), will start exploring the same branch as much as possible before moving to the next closest branch:\n",
    "\n",
    "In the preceding figure, you can see the search order of the DFS technique. Starting from the root node ($1$), DFS will go to the closest node ($2$) and explore all the way to the end of the branch ($3$) on the third depth before going back to the node ($2$) and finish by exploring its second branch ($4$). Then, it will move back to the second depth and start the same process with the next branch ($6$) before finishing with the last branch ($7$).\n",
    "\n",
    "Now, suppose we have a tree defined by its root and a function that generates all the successor nodes from the root. In the following example, each node has a value and a depth. We start from 1 and may either increase the value by $1$ or $2$. Our goal is to reach the value $5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = {'value': 1, 'depth': 1}\n",
    "\n",
    "def succ(node):\n",
    "    if node['value'] == 5:\n",
    "        return []\n",
    "    elif node['value'] == 4:\n",
    "        return [{'value': 5, 'depth': node['depth']+1}]\n",
    "    else:\n",
    "        return [{'value': node['value'] + 1, 'depth': node['depth'] + 1,\n",
    "                 'value': node['value'] + 2, 'depth': node['depth'] + 1\n",
    "                }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code snippet, we have initialized the root node as having a value and depth of $1$. Then, we created a function called `succ` that takes a node as input. This function will have $3$ different cases:\n",
    "\n",
    "  * If the input node value is $5$, then return nothing as we will have already reached our goal $(5)$.\n",
    "  * If the input node value is $4$, then return the value $5$ and add $1$ to the current depth.\n",
    "  * If the value is anything else, then add $1$ to the depth and create two cases for the value, $+1$ and $+2$.\n",
    "  \n",
    "First, we will perform BFS, as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_tree(node):\n",
    "    nodes_to_visit = [node]\n",
    "    visited_nodes = []\n",
    "    while len(nodes_to_visit) > 0:\n",
    "        current_node = nodes_to_visit.pop(0)\n",
    "        visited_nodes.append(current_node)\n",
    "        nodes_to_visit.extend(succ(current_node))\n",
    "    return visited_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code snippet, we have implemented the `bfs_tree` function by taking a node as input. This function can be broken down into three parts:\n",
    "\n",
    "The **first part** is initializing the `nodes_to_visit` and `visited_nodes` variables.\n",
    "\n",
    "The **second part** is where BFS is implemented:\n",
    "\n",
    "  * The `current_node` variable takes away the first element of the `nodes_to_visit` variable.\n",
    "  * The `visited_nodes` variable adds this element to its list.\n",
    "  * The `nodes_to_visit` variable adds the newly generated nodes from the call of `succ` with the `current_node` as input to it.\n",
    "  \n",
    "The preceding three instructions are wrapped into a loop defined by the number of elements inside the `nodes_to_visit` variable. As long as `nodes_to_visit` has at least one element, then the loop will keep going.\n",
    "\n",
    "The **third part**, which is the end of the function, will return the entire list of values from the `visited_nodes` variable.\n",
    "\n",
    "Let's run the snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': 1, 'depth': 1}, {'value': 3, 'depth': 2}, {'value': 5, 'depth': 3}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfs_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, BFS is searching through the values of the same depth before moving to the next level of depth and exploring the values of it. Notice how depth and value are increasing in sequence. This will not be the case in DFS.\n",
    "\n",
    "If we had to traverse a graph instead of a directed rooted tree, BFS would look different: whenever we visit a node, we would have to check whether the node had been visited before. If the node had been visited before, we would simply ignore it.\n",
    "\n",
    "In this chapter, we will only use Breadth First Traversal on trees. DFS is surprisingly similar to BFS. The difference between DFS and BFS is the sequence in which you access the nodes. While BFS visits all the children of a node before visiting any other nodes, DFS digs deep into the tree.\n",
    "\n",
    "Have a look at the following example, where we're implementing DFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_tree(node):\n",
    "    nodes_to_visit = [node]\n",
    "    visited_nodes = []\n",
    "    while len(nodes_to_visit) > 0:\n",
    "        current_node = nodes_to_visit.pop()\n",
    "        visited_nodes.append(current_node)\n",
    "        nodes_to_visit.extend(succ(current_node))\n",
    "    return visited_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code snippet, we have implemented the `dfs_tree` function by taking a node as input. This function can be broken down into three parts:\n",
    "\n",
    "The **first part** is initializing the `nodes_to_visit` and `visited_nodes` variables.\n",
    "\n",
    "The **second part** is where DFS is implemented:\n",
    "\n",
    "  * The `current_node` variable takes away the last element of the `nodes_to_visit` variable.\n",
    "  * The `visited_nodes variable` adds this element to its list.\n",
    "  * The `nodes_to_visit` variable adds the newly generated nodes from the call of `succ` with `current_node` as input to it.\n",
    "  \n",
    "The preceding three instructions are wrapped into a loop defined by the number of elements inside the `nodes_to_visit` variable. As long as `nodes_to_visit` has at least one element, then the loop will keep going.\n",
    "\n",
    "At the end, that is at the **third part**, the function will return the entire list of values from `visited_nodes`.\n",
    "\n",
    "As you can see, the main difference between BFS and DFS is the order in which we took an element out of `nodes_to_visit`. For BFS, we take the first element, whereas for DFS, we take the last one.\n",
    "\n",
    "Let's run the snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': 1, 'depth': 1}, {'value': 3, 'depth': 2}, {'value': 5, 'depth': 3}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the DFS algorithm digs deep fast (the depth reaches higher values faster than BFS). It does not necessarily find the shortest path first, but it is guaranteed to find a leaf before exploring a second path.\n",
    "\n",
    "In game AI, the BFS algorithm is often better for the evaluation of game states because DFS may get lost. Imagine starting a chess game, where a DFS algorithm may easily get lost in exploring the options for a move.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the State Space of a Game\n",
    "\n",
    "Let's explore the state space of a simple game: tic-tac-toe. A state space is the set of all possible configurations of a game, which, in this case, means all the possible moves.\n",
    "\n",
    "In tic-tac-toe, a 3x3 game board is given. Two players play this game. One plays with the sign X, while the other plays with the sign O. X starts the game, and each player makes a move after the other. The goal of the game is to get three of your own signs horizontally, vertically, or diagonally.\n",
    "\n",
    "Let's denote the cells of the tic-tac-toe board, as follows:\n",
    "\n",
    "![Figure 1.6](img/fig1_06.jpg)\n",
    "\n",
    "In the following example, $X$ started at position $1$. $O$ retaliated at position $5$, $X$ made a move at position $9$, and then $O$ moved to position $3$:\n",
    "\n",
    "![Figure 1.7](img/fig1_07.jpg)\n",
    "\n",
    "This was a mistake by the second player, because now $X$ is forced to place a sign on cell $7$, creating two future scenarios for winning the game. It does not matter whether $O$ defends by moving to cell $4$ or $8$ – X will win the game by selecting the other unoccupied cell.\n",
    "\n",
    "  > You can try out the game at [http://www.half-real.net/tictactoe/](http://www.half-real.net/tictactoe/).\n",
    "  \n",
    "For simplicity, we will only explore the state space belonging to the cases when the AI player starts. We will start with an AI player who plays randomly, placing a sign in an empty cell. After playing with this AI player, we will create a complete decision tree. Once we generate all possible game states, you will experience their combinatorial explosion. As our goal is to make these complexities simple, we will use several different techniques to make the AI player smarter and reduce the size of the decision tree.\n",
    "\n",
    "By the end of this experiment, we will have a decision tree that has fewer than 200 different game endings and, as a bonus, the AI player will never lose a single game.\n",
    "\n",
    "To make a random move, you will have to know how to choose a random element from a list using Python. We will use the `choice` function of the `random` library to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "choice([2, 4, 6, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the output is `2`, but for you, it can be any number from the list.\n",
    "\n",
    "The output of the choice function is a random element of the list.\n",
    "\n",
    "  > We will use the factorial notation in the following section.\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Number of Possible States in a Tic-Tac-Toe Game\n",
    "\n",
    "Make a rough estimate of the number of possible states on each level of the state space of the tic-tac-toe game:\n",
    "\n",
    "  * In our estimation, we will not stop until all of the cells of the board have been filled. A player might win before the game ends, but for the sake of uniformity, we will continue the game.\n",
    "  * The first player will choose one of the nine cells. The second player will choose one out of the eight remaining cells. The first player can then choose one out of the seven remaining cells. This goes on until either player wins the game, or the first player is forced to make the ninth and last move.\n",
    "  * The number of possible decision sequences is, therefore, $9! = 362,880$. A few of these sequences are invalid because a player may win the game in fewer than nine moves. It takes at least five moves to win a game because the first player needs to move three times.\n",
    "  * To calculate the exact size of the state space, we have to calculate the number of games that are won in five, six, seven, and eight steps. This calculation is simple, but due to its brute-force nature, it is beyond our scope. Therefore, we will settle on the magnitude of the state space.\n",
    "    > After generating all possible tic-tac-toe games, researchers counted $255,168$ possible games. Out of those games, $131,184$ were won by the first player, $77,904$ were won by the second player, and $46,08$0 games ended with a draw. Visit [http://www.half-real.net/tictactoe/allgamesoftictactoe.zip to download all possible tic-tac-toe games](http://www.half-real.net/tictactoe/allgamesoftictactoe.zip to download all possible tic-tac-toe games).\n",
    "    \n",
    "Even a simple game such as tic-tac-toe has a lot of states. Just imagine how hard it would be to start exploring all possible chess games. Therefore, we can conclude that brute-force searching is rarely ideal.\n",
    "\n",
    "**Go to Exercise 1.02**\n",
    "\n",
    "By completing this exercise, you have seen that even an opponent who is playing randomly may win from time to time if their opponent makes a mistake.\n",
    "\n",
    "**Go to Activity 1.01**\n",
    "\n",
    "**Go to Exercise 1.03**\n",
    "\n",
    "## Defending the AI against Losses\n",
    "\n",
    "In the next activity, we will make the AI computer player play better compared to our previous exercise so that we can reduce the state space and the number of losses.\n",
    "\n",
    "**Go to Activity 1.02**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the important techniques that we applied to reduce the state space so far:\n",
    "\n",
    "  * **Empirical simplification**: We accepted that the optimal first move is a corner move. We simply hardcoded a move instead of considering alternatives to focus on other aspects of the game. In more complex games, empirical moves are often misleading. The most famous chess AI victories often contain a violation of the common knowledge of chess grand masters.\n",
    "  * **Symmetry**: After we started with a corner move, we noticed that positions 1, 3, 7, and 9 were equivalent to the perspective of winning the game. Even though we didn't take this idea further, we noticed that we could even rotate the table to reduce the state space even further and consider all four corner moves as the exact same move.\n",
    "  * **Reduction in different permutations leading to the same state**: Suppose we can make the moves A or B and suppose our opponent makes move X, where X is not equal to either move A or B. If we explore the sequence A, X, B, and we start exploring the sequence B, X, then we don't have to consider the sequence B, X, A. This is because the two sequences lead to the exact same game state, and we have already explored a state containing these three moves before, that is, A, X, and B. The order of the sequence doesn't matter as it leads to the same result. This allows us to significantly reduce the number of possible moves.\n",
    "  * **Forced moves for the player**: When a player collects two signs horizontally, vertically, or diagonally, and the third cell in the row is empty, we are forced to occupy that empty cell either to win the game or to prevent the opponent from winning the game. Forced moves may imply other forced moves, which reduces the state space even further.\n",
    "  * **Forced moves for the opponent**: When a move from the opponent is clearly optimal, it does not make sense to consider scenarios where the opponent does not make the optimal move. When the opponent can win the game by occupying a cell, it does not matter whether we go on a long exploration of the cases when the opponent misses the optimal move. We save a lot less by not exploring cases when the opponent fails to prevent us from winning the game. This is because after the opponent makes a mistake, we will simply win the game.\n",
    "  * **Random move**: When we cannot decide and don't have the capacity to search, we move randomly. Random moves are almost always inferior to a search-based educated guess, but at times, we have no other choice.\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristics\n",
    "\n",
    "In this section, we will formalize informed search techniques by defining and applying heuristics to guide our search. We will be looking at heuristics and creating them in the sections ahead.\n",
    "\n",
    "## Uninformed and Informed Searches\n",
    "\n",
    "In the tic-tac-toe example, we implemented a greedy algorithm that first focused on winning, and then focused on not losing. When it comes to winning the game immediately, the greedy algorithm is optimal because there is never a better step than winning the game. When it comes to not losing, it matters how we avoid the loss. Our algorithm simply choses a random safe move without considering how many winning opportunities we have created.\n",
    "\n",
    "BFS and DFS are part of uninformed searching because they consider all possible states in the game, which can be very time-consuming. On the other hand, heuristic informed searches will explore the space of available states intelligently in order to reach the goal faster.\n",
    "\n",
    "## Creating Heuristics\n",
    "\n",
    "If we want to make better decisions, we apply heuristics to guide the search in the right direction by considering long-term benefits. This way, we can make a more informed decision in the present based on what could happen in the future. This can also help us solve problems faster.\n",
    "\n",
    "We can construct heuristics as follows:\n",
    "\n",
    "  * In terms of the utility of making a move in the game\n",
    "  * In terms of the utility of a given game state from the perspective of a player\n",
    "  * In terms of the distance from our goal\n",
    "  \n",
    "Heuristics are functions that evaluate a game state or a transition to a new game state based on their utility. Heuristics are the cornerstones of making a search problem informed.\n",
    "\n",
    "In this course, we will use utility and cost as negated terms. Maximizing utility and minimizing the cost of a move are considered synonyms.\n",
    "\n",
    "A commonly used example of a heuristic evaluation function occurs in pathfinding problems. Suppose we are looking to reach a destination or a goal. Each step has an associated cost symbolizing the travel distance. Our goal is to minimize the cost of reaching the destination or goal (minimizing the travel distance).\n",
    "\n",
    "One example of heuristic evaluation for solving this pathfinding problem will be to take the coordinates between the current state (position) and the goal (destination) and calculate the distance between these two points. The distance between two points is the length of the straight line connecting the points. This heuristic is called the Euclidean distance (as shown in the Figure 1.10).\n",
    "\n",
    "Now, suppose we define our pathfinding problem in a maze, where we can only move up, down, left, or right. There are a few obstacles in the maze that block our moves, so using the Euclidean distance is not ideal. A better heuristic would be to use the Manhattan distance, which can be defined as the sum of the horizontal and vertical distances between the coordinates of the current state and the goal.\n",
    "\n",
    "## Admissible and Non-Admissible Heuristics\n",
    "\n",
    "The two heuristics we just defined regarding pathfinding problems are called admissible heuristics when they're used on their given problem domain.\n",
    "\n",
    "Admissible means that we may underestimate the cost of reaching the end state but that we never overestimate it. Later, we will explore an algorithm that finds the shortest path between the current state and the goal state. The optimal nature of this algorithm depends on whether we can define an admissible heuristic function.\n",
    "\n",
    "An example of a non-admissible heuristic would be the Euclidean distance that's applied to a real-world map.\n",
    "\n",
    "Imagine that we want to move from point A to point B in the city of Manhattan. Here, the Euclidean distance will be the straight line between the two points, but, as we know, we cannot just go straight in a city such as Manhattan (unless we can fly). In this case, the Euclidean distance is underestimating the cost of reaching the goal. A better heuristic would be the Manhattan distance:\n",
    "\n",
    "![Figure 1.10](img/fig1_10.jpg)\n",
    "\n",
    "Since we overestimated the cost of traveling from the current node to the goal, the Euclidean distance is not admissible when we cannot move diagonally.\n",
    "\n",
    "## Heuristic Evaluation\n",
    "\n",
    "We can create a heuristic evaluation for our tic-tac-toe game state from the perspective of the starting player by defining the utility of a move.\n",
    "\n",
    "### Heuristic 1: Simple Evaluation of the Endgame\n",
    "\n",
    "Let's define a simple heuristic by evaluating a board. We can set the utility for the game as one of the following:\n",
    "\n",
    "  * $+1$, if the state implies that the AI player will win the game\n",
    "  * $-1$, if the state implies that the AI player will lose the game\n",
    "  * $0$, if a draw has been reached or no clear winner can be identified from the current state\n",
    "  \n",
    "This heuristic is simple because anyone can look at a board and analyze whether a player is about to win.\n",
    "\n",
    "The utility of this heuristic depends on whether we can play many moves in advance. Notice that we cannot even win the game within five steps. In Activity 1.01, we saw that by the time we reach step five, we have 13,680 possible combinations leading to it. In most of these 13,680 cases, our heuristic returns zero as we can't identify a clear winner yet.\n",
    "\n",
    "If our algorithm does not look deeper than these five steps, we are completely clueless on how to start the game. Therefore, we should invent a better heuristic.\n",
    "\n",
    "### Heuristic 2: Utility of a Move\n",
    "\n",
    "Let's change the utility for the game as follows:\n",
    "\n",
    "  * Two AI signs in a row, column, or diagonal, and the third cell is empty: +1000 for the empty cell.\n",
    "  * The opponent has two signs in a row, column, or diagonal, and the third cell is empty: +100 for the empty cell.\n",
    "  * One AI sign in a row, column, or diagonal, and the other two cells are empty: +10 for the empty cells.\n",
    "  * No AI or opponent signs in a row, column, or diagonal: +1 for the empty cells.\n",
    "  * Occupied cells get a value of minus infinity. In practice, due to the nature of the rules, -1 will also do.\n",
    "  \n",
    "Why do we use a multiplicative factor of 10 for the first three rules compared to the fourth one? We do this because there are eight possible ways of making three in a row, column, and diagonal. So, even by knowing nothing about the game, we are certain that a lower-level rule may not accumulate to overriding a higher-level rule. In other words, we will never defend against the opponent's moves if we can win the game.\n",
    "\n",
    "  > **Note**  \n",
    "  > As the job of our opponent is also to win, we can compute this heuristic from the opponent's point of view. Our task is to maximize this value, too, so that we can defend against the optimal plays of our opponent. This is the idea behind the Minmax algorithm as well, which will be covered later in this chapter. If we wanted to convert this heuristic into a heuristic that describes the current board, we could compute the heuristic value for all open cells and take the maximum of the values for the AI character so that we can maximize our utility.\n",
    "\n",
    "For each board, we will create a utility matrix.\n",
    "\n",
    "For example, consider the following board, with $O$ signs as the player and $X$ signs as the AI:\n",
    "\n",
    "![Figure 1.11](img/fig1_11.jpg)\n",
    "\n",
    "From here, we can construct its utility matrix shown in the following figure:\n",
    "\n",
    "![Figure 1.12](img/fig1_12.jpg)\n",
    "\n",
    "On the second row, the left cell is not beneficial if we were to select it. Note that if we had a more optimal utility function, we would reward blocking the opponent.\n",
    "\n",
    "The two cells of the third column both get a 10-point boost for two in a row.\n",
    "\n",
    "The top-right cell also gets 100 points for defending against the diagonal of the opponent.\n",
    "\n",
    "From this matrix, evidently, we should choose the top-right move. At any stage of the game, we were able to define the utility of each cell; this was a static evaluation of the heuristic function.\n",
    "\n",
    "We can use this heuristic to guide us toward an optimal next move or to give a more educated score on the current board by taking the maximum of these values. We have technically used parts of this heuristic in the form of hardcoded rules. Note, though, that the real utility of heuristics is not the static evaluation of a board, but the guidance it provides for limiting the search space.\n",
    "\n",
    "**Go to Exercise 1.04**\n",
    "\n",
    "## Using Heuristics for an Informed Search\n",
    "\n",
    "We have not experienced the real power of heuristics yet as we made moves without the knowledge of the effects of our future moves, thereby effecting reasonable play from our opponents.\n",
    "\n",
    "Therefore, a more accurate heuristic leads to more losses than simply hardcoding the first two moves in the game. Note that in the previous section, we selected these two moves based on the statistics we generated based on running the game with fixed first moves. This approach is essentially what heuristic search should be all about.\n",
    "\n",
    "## Types of Heuristics\n",
    "\n",
    "Static evaluation cannot compete with generating hundreds of thousands of future states and selecting a play that maximizes our rewards. This is because our heuristics are not exact and are likely not admissible either.\n",
    "\n",
    "We saw in the preceding exercise that heuristics are not always optimal. We came up with rules that allowed the AI to always win the game or finish with a draw. These heuristics allowed the AI to win very frequently, at the expense of losing in a few cases. A heuristic is said to be admissible if we underestimate the utility of a game state, but we never overestimate it.\n",
    "\n",
    "In the tic-tac-toe example, we likely overestimated the utility in a few game states, and why is that? Because we ended up with a loss 12 times. A few of the game states that led to a loss had a maximum heuristic score. To prove that our heuristic is not admissible, all we need to do is find a potentially winning game state that we ignored while choosing a game state that led to a loss.\n",
    "\n",
    "There are two more features that describe heuristics, that is, optimal and complete:\n",
    "\n",
    "  * Optimal heuristics always find the best possible solution.\n",
    "  * Complete heuristics has two definitions, depending on how we define the problem domain. In a loose sense, a heuristic is said to be complete if it always finds a solution. In a strict sense, a heuristic is said to be complete if it finds all possible solutions. Our tic-tac-toe heuristic is not complete because we ignored many possible winning states on purpose, favoring a losing state.\n",
    "  \n",
    "As you can see, defining an accurate heuristic requires a lot of details and thinking in order to obtain a perfect AI agent. If you are not correctly estimating the utility in the game states, then you can end up with an AI underperforming hardcoded rules.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the A* Algorithm\n",
    "\n",
    "A* is a complete and optimal heuristic search algorithm that finds the shortest possible path between the current game state and the winning state. The definition of complete and optimal in this state are as follows:\n",
    "\n",
    "  * Complete means that A* always finds a solution.\n",
    "  * Optimal means that A* will find the best solution.\n",
    "  \n",
    "To set up the A* algorithm, we need the following:\n",
    "\n",
    "  * An initial state\n",
    "  * A description of the goal states\n",
    "  * Admissible heuristics to measure progress toward the goal state\n",
    "  * A way to generate the next steps toward the goal\n",
    "  \n",
    "Once the setup is complete, we execute the A* algorithm using the following steps on the initial state:\n",
    "\n",
    "  1. We generate all possible next steps.\n",
    "  2. We store these children in the order of their distance from the goal.\n",
    "  3. We select the child with the best score first and repeat these three steps on the child with the best score as the initial state. This is the shortest path to get to a node from the starting node.\n",
    "  \n",
    "Let's take, for example, the following figure:\n",
    "\n",
    "![Figure 1.15](img/fig1_15.jpg)\n",
    "\n",
    "The first step will be to generate all the possible moves from the origin, $A$, which is moving from $A$ to $B (A,B)$ or to $C (A,C)$.\n",
    "\n",
    "The second step is to use the heuristic (the distance) to order the two possible moves, $(A,B)$, with 10, which is shorter compared to $(A,C)$ with 100.\n",
    "\n",
    "The third step is to choose the shortest heuristic, which is $(A,B)$, and move to $B$.\n",
    "\n",
    "Now, we will repeat the same steps with $B$ as the origin.\n",
    "\n",
    "At the end, we will reach the goal $F$ with the path $(A,B,D,F)$ with a cumulative heuristic of 24. If we were following another path, such as $(A,B,E,F)$, the cumulative heuristic will be 30, which is higher than the shortest path.\n",
    "\n",
    "We did not even look at $(A,C,F)$ as it was already way over the shortest path.\n",
    "\n",
    "In pathfinding, a good heuristic is the Euclidean distance. If the current node is $(x, y)$ and the goal node is $(u, v)$, then we have the following:\n",
    "\n",
    "```Python\n",
    "distance_from_end( node ) = sqrt( abs( x – u ) ** 2 + abs( y – v ) ** 2 )\n",
    "```\n",
    "\n",
    "Here, `distance_from_end(node)` is an admissible heuristic estimation showing how far we are from the goal node.\n",
    "\n",
    "We also have the following:\n",
    "\n",
    "  * `sqrt` is the square root function. Do not forget to import it from the `math` library.\n",
    "  * `abs` is the absolute value function, that is, `abs( -2 ) = abs( 2 ) = 2`.\n",
    "  * `x ** 2` is $x$ raised to the second power.\n",
    "  \n",
    "  \n",
    "We will use the `distance_from_start` matrix to store the distances from the start node. In the algorithm, we will refer to this cost matrix as `distance_from_start(n1)`. For any node, $n1$, that has coordinates $(x1, y1)$, this distance is equivalent to `distance_from_start[x1][y1]`.\n",
    "\n",
    "We will use the `succ(n)` notation to generate a list of successor nodes from $n$.\n",
    "\n",
    "Have a look at the pseudocode of the algorithm:\n",
    "\n",
    "```Python\n",
    "frontier = [start], internal = {}\n",
    "# Initialize the costs matrix with each cell set to infinity.\n",
    "# Set the value of distance_from_start(start) to 0. \n",
    "while frontier is not empty: \n",
    "    \"\"\"\n",
    "    notice n has the lowest estimated total \n",
    "    distance between start and end.\n",
    "    \"\"\"\n",
    "    n = frontier.pop()\n",
    "    # We'll learn later how to reconstruct the shortest path\n",
    "    if n == end: \n",
    "        return the shortest path. \n",
    "    internal.add(n) \n",
    "    for successor s in succ(n): \n",
    "        if s in internal: \n",
    "            continue # The node was already examined\n",
    "        new_distance = distance_from_start(n) + distance(n, s) \n",
    "        if new_distance >= distance_from_start(s): \n",
    "            \"\"\"\n",
    "            This path is not better than the path we have \n",
    "            already examined.\n",
    "            \"\"\"\n",
    "            continue \n",
    "        if s is a member of frontier:\n",
    "            update the priority of s\n",
    "        else:\n",
    "            Add s to frontier.\n",
    "```\n",
    "\n",
    "Regarding the retrieval of the shortest path, we can use the `costs` matrix. This matrix contains the distance of each node on the path from the start node. As cost always decreases when walking backward, all we need to do is start with the end node and walk backward greedily toward decreasing costs:\n",
    "\n",
    "```Python\n",
    "path = [end_node], distance = get_distance_from_start( end_node )\n",
    "while the distance of the last element in the path is not 0:\n",
    "    for each neighbor of the last node in path:\n",
    "        new_distance = get_distance_from_start( neighbor )\n",
    "        if new_distance < distance: \n",
    "            add neighbor to path, and break out from the for loop\n",
    "return path\n",
    "```\n",
    "\n",
    "A* shines when we have one start state and one goal state. The complexity of the A* algorithm is $O( E )$, where $E$ stands for all possible edges in the field. In our example, we have up to four edges leaving any node: up, down, left, and right.\n",
    "\n",
    "  > **Note**  \n",
    "  > To sort the frontier list in the proper order, we must use a special Python data structure: a priority queue.\n",
    "  \n",
    "Have a look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'second item'), (2, 'first item')]\n",
      "(1, 'second item')\n",
      "[(2, 'first item')]\n"
     ]
    }
   ],
   "source": [
    "# Import heapq to access the priority queue\n",
    "import heapq\n",
    "\n",
    "# create a list to store the data\n",
    "data = []\n",
    "\n",
    "# Use heapq.heappush to push (priorityInt, value) pairs to the queue\n",
    "\n",
    "heapq.heappush(data, (2, 'first item'))\n",
    "heapq.heappush(data, (1, 'second item'))\n",
    "\n",
    "# The tuples are stored in data in the order of ascending priority\n",
    "print(data)\n",
    "\n",
    "# heapq.heappop pops the item with the lowest score from the queue\n",
    "print(heapq.heappop(data))\n",
    "\n",
    "# The data still contains the second item.\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it important that the heuristic being used by the algorithm is admissible?\n",
    "\n",
    "Because this is how we guarantee the optimal nature of the algorithm. For any node $x$, we are measuring the sum of the distances from the start node to $x$. This is the estimated distance from $x$ to the end node. If the estimation never overestimates the distance from $x$ to the end node, we will never overestimate the total distance. Once we are at the goal node, our estimation is zero, and the total distance from the start to the end becomes an exact number.\n",
    "\n",
    "We can be sure that our solution is optimal because there are no other items in the priority queue that have a lower estimated cost. Given that we never overestimate our costs, we can be sure that all of the nodes in the frontier of the algorithm have either similar total costs or higher total costs than the path we found.\n",
    "\n",
    "In the following example, we can see how to implement the A* algorithm to find the path with the lowest cost:\n",
    "\n",
    "![Figure 1.16](img/fig1_16.jpg)\n",
    "\n",
    "We import `math` and `heapq`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse the initialization code from Steps 2 and 3 of the **Exercise 1.05**.\n",
    "\n",
    "  > **Note** \n",
    "  > Omit the function to update costs because we will do so within the A* algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (7, 9)\n",
    "start = (5, 3)\n",
    "end = (6, 9)\n",
    "obstacles = {(3, 4), (3, 5), (3, 6), (3, 7), (3, 8),\n",
    "            (4, 5), (5, 5), (5, 7), (5, 9), (6, 2),\n",
    "            (6, 3), (6, 4), (6, 5), (6, 7), (7, 7)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successors(state, visited_nodes):\n",
    "    (row, col) = state\n",
    "    (max_row, max_col) = size\n",
    "    succ_states = []\n",
    "    if row > 1:\n",
    "        succ_states += [(row-1, col)]\n",
    "    if col > 1:\n",
    "        succ_states += [(row, col-1)]\n",
    "    if row < max_row:\n",
    "        succ_states += [(row+1, col)]\n",
    "    if col < max_col:\n",
    "        succ_states += [(row, col+1)]\n",
    "    return [s for s in succ_states if s not in visited_nodes if s not in obstacles]\n",
    "\n",
    "def initialize_costs(size, start):\n",
    "    (h, w) = size\n",
    "    costs = [[math.inf] * w for i in range(h)]\n",
    "    (x, y) = start\n",
    "    costs[x-1][y-1] = 0\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the A* algorithm's frontier and internal lists. For `frontier`, we will use a Python `PriorityQueue`. Do not execute this code directly; *Use these four lines inside the A* search function*:\n",
    "\n",
    "```Python\n",
    "frontier = []\n",
    "internal = set()\n",
    "heapq.heappush(frontier, (0, start))\n",
    "costs = initialize_costs(size, start)\n",
    "```\n",
    "\n",
    "Implement a heuristic function that measures the distance between the current node and the goal node using the algorithm we saw in the heuristic section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_heuristic(node, goal):\n",
    "    x, y = node\n",
    "    u, v = goal\n",
    "    return math.sqrt(abs(x - u) ** 2 + abs(y - v) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the A* algorithm into functioning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(start, end):\n",
    "    frontier = []\n",
    "    internal = set()\n",
    "    heapq.heappush(frontier, (0, start))\n",
    "    costs = initialize_costs(size, start)\n",
    "    \n",
    "    def get_distance_from_start(node):\n",
    "        return costs[node[0] - 1][node[1] - 1]\n",
    "    \n",
    "    def set_distance_from_start(node, new_distance):\n",
    "        costs[node[0] - 1][node[1] - 1] = new_distance\n",
    "        \n",
    "    while len(frontier) > 0:\n",
    "        (priority, node) = heapq.heappop(frontier)\n",
    "        if node == end:\n",
    "            return priority\n",
    "        internal.add(node)\n",
    "        successor_nodes = successors(node, internal)\n",
    "        \n",
    "        for s in successor_nodes:\n",
    "            new_distance = get_distance_from_start(node) + 1\n",
    "            if new_distance < get_distance_from_start(s):\n",
    "                set_distance_from_start(s, new_distance)\n",
    "                # Filter previous entries of s\n",
    "                frontier = [n for n in frontier if s != n[1]]\n",
    "                heapq.heappush(frontier, (new_distance + distance_heuristic(s, end), s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astar(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few differences between our implementation and the original algorithm.\n",
    "\n",
    "We defined a `distance_from_start` function to make it easier and more semantic to access the `costs` matrix. Note that we number the node indices starting with 1, while in the matrix, indices start with zero. Therefore, we subtract 1 from the node values to get the indices.\n",
    "\n",
    "When generating the successor nodes, we automatically ruled out nodes that are in the internal set. `successors = succ(node, internal)` makes sure that we only get the neighbors whose examination is not closed yet, meaning that their score is not necessarily optimal.\n",
    "\n",
    "Therefore, we may skip the step check since internal nodes will never end up in `succ(n)`.\n",
    "\n",
    "Since we are using a priority queue, we must determine the estimated priority of nodes before inserting them. However, we will only insert the node in the frontier if we know that this node does not have an entry with a lower score.\n",
    "\n",
    "It may happen that nodes are already in the frontier queue with a higher score. In this case, we remove this entry before inserting it into the right place in the priority queue. When we find the end node, we simply return the length of the shortest path instead of the path itself.\n",
    "\n",
    "To follow what the A* algorithm does, execute the following example code and observe the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_verbose(start, end):\n",
    "    frontier = []\n",
    "    internal = set()\n",
    "    heapq.heappush(frontier, (0, start))\n",
    "    costs = initialize_costs(size, start)\n",
    "    \n",
    "    def get_distance_from_start(node):\n",
    "        return costs[node[0] - 1][node[1] - 1]\n",
    "    \n",
    "    def set_distance_from_start(node, new_distance):\n",
    "        costs[node[0] - 1][node[1] -1] = new_distance\n",
    "        \n",
    "    steps = 0\n",
    "    \n",
    "    while len(frontier) > 0:\n",
    "        steps += 1\n",
    "        print('step ', steps, '. frontier: ', frontier)\n",
    "        (priority, node) = heapq.heappop(frontier)\n",
    "        print('node ', node, 'has been popped from frontier with priority', priority)\n",
    "        \n",
    "        if node == end:\n",
    "            print('Optimal path found. Steps: ', steps)\n",
    "            print('Costs matrix: ', costs)\n",
    "            return priority\n",
    "        \n",
    "        internal.add(node)\n",
    "        successor_nodes = successors(node, internal)\n",
    "        print('successor_nodes', successor_nodes)\n",
    "        \n",
    "        for s in successor_nodes:\n",
    "            new_distance = get_distance_from_start(node) + 1\n",
    "            print('s:', s, 'new distance:', new_distance, ' old distance:',\n",
    "                  get_distance_from_start(s))\n",
    "            if new_distance < get_distance_from_start(s):\n",
    "                set_distance_from_start(s, new_distance)\n",
    "                # filter previous entries of s\n",
    "                frontier = [n for n in frontier if s != n[1]]\n",
    "                new_priority = new_distance + distance_heuristic(s, end)\n",
    "                heapq.heappush(frontier, (new_priority, s))\n",
    "                print('Node', s, 'has been pushed to frontier with priority', new_priority)\n",
    "                \n",
    "    print('Frontier', frontier)\n",
    "    print('Internal', internal)\n",
    "    print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  1 . frontier:  [(0, (5, 3))]\n",
      "node  (5, 3) has been popped from frontier with priority 0\n",
      "successor_nodes [(4, 3), (5, 2), (5, 4)]\n",
      "s: (4, 3) new distance: 1  old distance: inf\n",
      "Node (4, 3) has been pushed to frontier with priority 7.324555320336759\n",
      "s: (5, 2) new distance: 1  old distance: inf\n",
      "Node (5, 2) has been pushed to frontier with priority 8.071067811865476\n",
      "s: (5, 4) new distance: 1  old distance: inf\n",
      "Node (5, 4) has been pushed to frontier with priority 6.0990195135927845\n",
      "step  2 . frontier:  [(6.0990195135927845, (5, 4)), (8.071067811865476, (5, 2)), (7.324555320336759, (4, 3))]\n",
      "node  (5, 4) has been popped from frontier with priority 6.0990195135927845\n",
      "successor_nodes [(4, 4)]\n",
      "s: (4, 4) new distance: 2  old distance: inf\n",
      "Node (4, 4) has been pushed to frontier with priority 7.385164807134504\n",
      "step  3 . frontier:  [(7.324555320336759, (4, 3)), (8.071067811865476, (5, 2)), (7.385164807134504, (4, 4))]\n",
      "node  (4, 3) has been popped from frontier with priority 7.324555320336759\n",
      "successor_nodes [(3, 3), (4, 2), (4, 4)]\n",
      "s: (3, 3) new distance: 2  old distance: inf\n",
      "Node (3, 3) has been pushed to frontier with priority 8.70820393249937\n",
      "s: (4, 2) new distance: 2  old distance: inf\n",
      "Node (4, 2) has been pushed to frontier with priority 9.280109889280517\n",
      "s: (4, 4) new distance: 2  old distance: 2\n",
      "step  4 . frontier:  [(7.385164807134504, (4, 4)), (8.071067811865476, (5, 2)), (8.70820393249937, (3, 3)), (9.280109889280517, (4, 2))]\n",
      "node  (4, 4) has been popped from frontier with priority 7.385164807134504\n",
      "successor_nodes []\n",
      "step  5 . frontier:  [(8.071067811865476, (5, 2)), (9.280109889280517, (4, 2)), (8.70820393249937, (3, 3))]\n",
      "node  (5, 2) has been popped from frontier with priority 8.071067811865476\n",
      "successor_nodes [(4, 2), (5, 1)]\n",
      "s: (4, 2) new distance: 2  old distance: 2\n",
      "s: (5, 1) new distance: 2  old distance: inf\n",
      "Node (5, 1) has been pushed to frontier with priority 10.06225774829855\n",
      "step  6 . frontier:  [(8.70820393249937, (3, 3)), (9.280109889280517, (4, 2)), (10.06225774829855, (5, 1))]\n",
      "node  (3, 3) has been popped from frontier with priority 8.70820393249937\n",
      "successor_nodes [(2, 3), (3, 2)]\n",
      "s: (2, 3) new distance: 3  old distance: inf\n",
      "Node (2, 3) has been pushed to frontier with priority 10.21110255092798\n",
      "s: (3, 2) new distance: 3  old distance: inf\n",
      "Node (3, 2) has been pushed to frontier with priority 10.615773105863909\n",
      "step  7 . frontier:  [(9.280109889280517, (4, 2)), (10.06225774829855, (5, 1)), (10.21110255092798, (2, 3)), (10.615773105863909, (3, 2))]\n",
      "node  (4, 2) has been popped from frontier with priority 9.280109889280517\n",
      "successor_nodes [(3, 2), (4, 1)]\n",
      "s: (3, 2) new distance: 3  old distance: 3\n",
      "s: (4, 1) new distance: 3  old distance: inf\n",
      "Node (4, 1) has been pushed to frontier with priority 11.246211251235321\n",
      "step  8 . frontier:  [(10.06225774829855, (5, 1)), (10.615773105863909, (3, 2)), (10.21110255092798, (2, 3)), (11.246211251235321, (4, 1))]\n",
      "node  (5, 1) has been popped from frontier with priority 10.06225774829855\n",
      "successor_nodes [(4, 1), (6, 1)]\n",
      "s: (4, 1) new distance: 3  old distance: 3\n",
      "s: (6, 1) new distance: 3  old distance: inf\n",
      "Node (6, 1) has been pushed to frontier with priority 11.0\n",
      "step  9 . frontier:  [(10.21110255092798, (2, 3)), (10.615773105863909, (3, 2)), (11.246211251235321, (4, 1)), (11.0, (6, 1))]\n",
      "node  (2, 3) has been popped from frontier with priority 10.21110255092798\n",
      "successor_nodes [(1, 3), (2, 2), (2, 4)]\n",
      "s: (1, 3) new distance: 4  old distance: inf\n",
      "Node (1, 3) has been pushed to frontier with priority 11.810249675906654\n",
      "s: (2, 2) new distance: 4  old distance: inf\n",
      "Node (2, 2) has been pushed to frontier with priority 12.06225774829855\n",
      "s: (2, 4) new distance: 4  old distance: inf\n",
      "Node (2, 4) has been pushed to frontier with priority 10.403124237432849\n",
      "step  10 . frontier:  [(10.403124237432849, (2, 4)), (11.0, (6, 1)), (10.615773105863909, (3, 2)), (11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (11.246211251235321, (4, 1))]\n",
      "node  (2, 4) has been popped from frontier with priority 10.403124237432849\n",
      "successor_nodes [(1, 4), (2, 5)]\n",
      "s: (1, 4) new distance: 5  old distance: inf\n",
      "Node (1, 4) has been pushed to frontier with priority 12.071067811865476\n",
      "s: (2, 5) new distance: 5  old distance: inf\n",
      "Node (2, 5) has been pushed to frontier with priority 10.65685424949238\n",
      "step  11 . frontier:  [(10.615773105863909, (3, 2)), (11.0, (6, 1)), (10.65685424949238, (2, 5)), (11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (12.071067811865476, (1, 4)), (11.246211251235321, (4, 1))]\n",
      "node  (3, 2) has been popped from frontier with priority 10.615773105863909\n",
      "successor_nodes [(2, 2), (3, 1)]\n",
      "s: (2, 2) new distance: 4  old distance: 4\n",
      "s: (3, 1) new distance: 4  old distance: inf\n",
      "Node (3, 1) has been pushed to frontier with priority 12.54400374531753\n",
      "step  12 . frontier:  [(10.65685424949238, (2, 5)), (11.0, (6, 1)), (11.246211251235321, (4, 1)), (11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (12.071067811865476, (1, 4)), (12.54400374531753, (3, 1))]\n",
      "node  (2, 5) has been popped from frontier with priority 10.65685424949238\n",
      "successor_nodes [(1, 5), (2, 6)]\n",
      "s: (1, 5) new distance: 6  old distance: inf\n",
      "Node (1, 5) has been pushed to frontier with priority 12.403124237432849\n",
      "s: (2, 6) new distance: 6  old distance: inf\n",
      "Node (2, 6) has been pushed to frontier with priority 11.0\n",
      "step  13 . frontier:  [(11.0, (2, 6)), (11.0, (6, 1)), (11.246211251235321, (4, 1)), (11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (12.071067811865476, (1, 4)), (12.403124237432849, (1, 5)), (12.54400374531753, (3, 1))]\n",
      "node  (2, 6) has been popped from frontier with priority 11.0\n",
      "successor_nodes [(1, 6), (2, 7)]\n",
      "s: (1, 6) new distance: 7  old distance: inf\n",
      "Node (1, 6) has been pushed to frontier with priority 12.8309518948453\n",
      "s: (2, 7) new distance: 7  old distance: inf\n",
      "Node (2, 7) has been pushed to frontier with priority 11.47213595499958\n",
      "step  14 . frontier:  [(11.0, (6, 1)), (11.47213595499958, (2, 7)), (11.246211251235321, (4, 1)), (11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (12.071067811865476, (1, 4)), (12.403124237432849, (1, 5)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1))]\n",
      "node  (6, 1) has been popped from frontier with priority 11.0\n",
      "successor_nodes [(7, 1)]\n",
      "s: (7, 1) new distance: 4  old distance: inf\n",
      "Node (7, 1) has been pushed to frontier with priority 12.06225774829855\n",
      "step  15 . frontier:  [(11.246211251235321, (4, 1)), (11.47213595499958, (2, 7)), (12.071067811865476, (1, 4)), (11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (12.54400374531753, (3, 1)), (12.403124237432849, (1, 5)), (12.8309518948453, (1, 6)), (12.06225774829855, (7, 1))]\n",
      "node  (4, 1) has been popped from frontier with priority 11.246211251235321\n",
      "successor_nodes [(3, 1)]\n",
      "s: (3, 1) new distance: 4  old distance: 4\n",
      "step  16 . frontier:  [(11.47213595499958, (2, 7)), (11.810249675906654, (1, 3)), (12.071067811865476, (1, 4)), (12.06225774829855, (7, 1)), (12.06225774829855, (2, 2)), (12.54400374531753, (3, 1)), (12.403124237432849, (1, 5)), (12.8309518948453, (1, 6))]\n",
      "node  (2, 7) has been popped from frontier with priority 11.47213595499958\n",
      "successor_nodes [(1, 7), (2, 8)]\n",
      "s: (1, 7) new distance: 8  old distance: inf\n",
      "Node (1, 7) has been pushed to frontier with priority 13.385164807134505\n",
      "s: (2, 8) new distance: 8  old distance: inf\n",
      "Node (2, 8) has been pushed to frontier with priority 12.123105625617661\n",
      "step  17 . frontier:  [(11.810249675906654, (1, 3)), (12.06225774829855, (2, 2)), (12.071067811865476, (1, 4)), (12.06225774829855, (7, 1)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1)), (12.403124237432849, (1, 5)), (13.385164807134505, (1, 7)), (12.123105625617661, (2, 8))]\n",
      "node  (1, 3) has been popped from frontier with priority 11.810249675906654\n",
      "successor_nodes [(1, 2), (1, 4)]\n",
      "s: (1, 2) new distance: 5  old distance: inf\n",
      "Node (1, 2) has been pushed to frontier with priority 13.602325267042627\n",
      "s: (1, 4) new distance: 5  old distance: 5\n",
      "step  18 . frontier:  [(12.06225774829855, (2, 2)), (12.06225774829855, (7, 1)), (12.071067811865476, (1, 4)), (12.123105625617661, (2, 8)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1)), (12.403124237432849, (1, 5)), (13.385164807134505, (1, 7)), (13.602325267042627, (1, 2))]\n",
      "node  (2, 2) has been popped from frontier with priority 12.06225774829855\n",
      "successor_nodes [(1, 2), (2, 1)]\n",
      "s: (1, 2) new distance: 5  old distance: 5\n",
      "s: (2, 1) new distance: 5  old distance: inf\n",
      "Node (2, 1) has been pushed to frontier with priority 13.94427190999916\n",
      "step  19 . frontier:  [(12.06225774829855, (7, 1)), (12.123105625617661, (2, 8)), (12.071067811865476, (1, 4)), (13.385164807134505, (1, 7)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1)), (12.403124237432849, (1, 5)), (13.602325267042627, (1, 2)), (13.94427190999916, (2, 1))]\n",
      "node  (7, 1) has been popped from frontier with priority 12.06225774829855\n",
      "successor_nodes [(7, 2)]\n",
      "s: (7, 2) new distance: 5  old distance: inf\n",
      "Node (7, 2) has been pushed to frontier with priority 12.071067811865476\n",
      "step  20 . frontier:  [(12.071067811865476, (1, 4)), (12.071067811865476, (7, 2)), (12.403124237432849, (1, 5)), (12.123105625617661, (2, 8)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1)), (13.94427190999916, (2, 1)), (13.602325267042627, (1, 2)), (13.385164807134505, (1, 7))]\n",
      "node  (1, 4) has been popped from frontier with priority 12.071067811865476\n",
      "successor_nodes [(1, 5)]\n",
      "s: (1, 5) new distance: 6  old distance: 6\n",
      "step  21 . frontier:  [(12.071067811865476, (7, 2)), (12.123105625617661, (2, 8)), (12.403124237432849, (1, 5)), (13.385164807134505, (1, 7)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1)), (13.94427190999916, (2, 1)), (13.602325267042627, (1, 2))]\n",
      "node  (7, 2) has been popped from frontier with priority 12.071067811865476\n",
      "successor_nodes [(7, 3)]\n",
      "s: (7, 3) new distance: 6  old distance: inf\n",
      "Node (7, 3) has been pushed to frontier with priority 12.082762530298218\n",
      "step  22 . frontier:  [(12.082762530298218, (7, 3)), (12.123105625617661, (2, 8)), (12.403124237432849, (1, 5)), (12.8309518948453, (1, 6)), (13.602325267042627, (1, 2)), (12.54400374531753, (3, 1)), (13.94427190999916, (2, 1)), (13.385164807134505, (1, 7))]\n",
      "node  (7, 3) has been popped from frontier with priority 12.082762530298218\n",
      "successor_nodes [(7, 4)]\n",
      "s: (7, 4) new distance: 7  old distance: inf\n",
      "Node (7, 4) has been pushed to frontier with priority 12.099019513592784\n",
      "step  23 . frontier:  [(12.099019513592784, (7, 4)), (12.123105625617661, (2, 8)), (12.403124237432849, (1, 5)), (12.8309518948453, (1, 6)), (13.602325267042627, (1, 2)), (12.54400374531753, (3, 1)), (13.94427190999916, (2, 1)), (13.385164807134505, (1, 7))]\n",
      "node  (7, 4) has been popped from frontier with priority 12.099019513592784\n",
      "successor_nodes [(7, 5)]\n",
      "s: (7, 5) new distance: 8  old distance: inf\n",
      "Node (7, 5) has been pushed to frontier with priority 12.123105625617661\n",
      "step  24 . frontier:  [(12.123105625617661, (2, 8)), (12.123105625617661, (7, 5)), (12.403124237432849, (1, 5)), (12.8309518948453, (1, 6)), (13.602325267042627, (1, 2)), (12.54400374531753, (3, 1)), (13.94427190999916, (2, 1)), (13.385164807134505, (1, 7))]\n",
      "node  (2, 8) has been popped from frontier with priority 12.123105625617661\n",
      "successor_nodes [(1, 8), (2, 9)]\n",
      "s: (1, 8) new distance: 9  old distance: inf\n",
      "Node (1, 8) has been pushed to frontier with priority 14.099019513592784\n",
      "s: (2, 9) new distance: 9  old distance: inf\n",
      "Node (2, 9) has been pushed to frontier with priority 13.0\n",
      "step  25 . frontier:  [(12.123105625617661, (7, 5)), (12.8309518948453, (1, 6)), (12.403124237432849, (1, 5)), (13.0, (2, 9)), (13.602325267042627, (1, 2)), (12.54400374531753, (3, 1)), (13.94427190999916, (2, 1)), (14.099019513592784, (1, 8)), (13.385164807134505, (1, 7))]\n",
      "node  (7, 5) has been popped from frontier with priority 12.123105625617661\n",
      "successor_nodes [(7, 6)]\n",
      "s: (7, 6) new distance: 9  old distance: inf\n",
      "Node (7, 6) has been pushed to frontier with priority 12.16227766016838\n",
      "step  26 . frontier:  [(12.16227766016838, (7, 6)), (12.403124237432849, (1, 5)), (12.54400374531753, (3, 1)), (12.8309518948453, (1, 6)), (13.602325267042627, (1, 2)), (13.385164807134505, (1, 7)), (13.94427190999916, (2, 1)), (14.099019513592784, (1, 8)), (13.0, (2, 9))]\n",
      "node  (7, 6) has been popped from frontier with priority 12.16227766016838\n",
      "successor_nodes [(6, 6)]\n",
      "s: (6, 6) new distance: 10  old distance: inf\n",
      "Node (6, 6) has been pushed to frontier with priority 13.0\n",
      "step  27 . frontier:  [(12.403124237432849, (1, 5)), (12.8309518948453, (1, 6)), (12.54400374531753, (3, 1)), (13.0, (2, 9)), (13.602325267042627, (1, 2)), (13.385164807134505, (1, 7)), (13.94427190999916, (2, 1)), (14.099019513592784, (1, 8)), (13.0, (6, 6))]\n",
      "node  (1, 5) has been popped from frontier with priority 12.403124237432849\n",
      "successor_nodes [(1, 6)]\n",
      "s: (1, 6) new distance: 7  old distance: 7\n",
      "step  28 . frontier:  [(12.54400374531753, (3, 1)), (12.8309518948453, (1, 6)), (13.0, (6, 6)), (13.0, (2, 9)), (13.602325267042627, (1, 2)), (13.385164807134505, (1, 7)), (13.94427190999916, (2, 1)), (14.099019513592784, (1, 8))]\n",
      "node  (3, 1) has been popped from frontier with priority 12.54400374531753\n",
      "successor_nodes [(2, 1)]\n",
      "s: (2, 1) new distance: 5  old distance: 5\n",
      "step  29 . frontier:  [(12.8309518948453, (1, 6)), (13.0, (2, 9)), (13.0, (6, 6)), (14.099019513592784, (1, 8)), (13.602325267042627, (1, 2)), (13.385164807134505, (1, 7)), (13.94427190999916, (2, 1))]\n",
      "node  (1, 6) has been popped from frontier with priority 12.8309518948453\n",
      "successor_nodes [(1, 7)]\n",
      "s: (1, 7) new distance: 8  old distance: 8\n",
      "step  30 . frontier:  [(13.0, (2, 9)), (13.602325267042627, (1, 2)), (13.0, (6, 6)), (14.099019513592784, (1, 8)), (13.94427190999916, (2, 1)), (13.385164807134505, (1, 7))]\n",
      "node  (2, 9) has been popped from frontier with priority 13.0\n",
      "successor_nodes [(1, 9), (3, 9)]\n",
      "s: (1, 9) new distance: 10  old distance: inf\n",
      "Node (1, 9) has been pushed to frontier with priority 15.0\n",
      "s: (3, 9) new distance: 10  old distance: inf\n",
      "Node (3, 9) has been pushed to frontier with priority 13.0\n",
      "step  31 . frontier:  [(13.0, (3, 9)), (13.602325267042627, (1, 2)), (13.0, (6, 6)), (14.099019513592784, (1, 8)), (13.94427190999916, (2, 1)), (15.0, (1, 9)), (13.385164807134505, (1, 7))]\n",
      "node  (3, 9) has been popped from frontier with priority 13.0\n",
      "successor_nodes [(4, 9)]\n",
      "s: (4, 9) new distance: 11  old distance: inf\n",
      "Node (4, 9) has been pushed to frontier with priority 13.0\n",
      "step  32 . frontier:  [(13.0, (4, 9)), (13.602325267042627, (1, 2)), (13.0, (6, 6)), (14.099019513592784, (1, 8)), (13.94427190999916, (2, 1)), (15.0, (1, 9)), (13.385164807134505, (1, 7))]\n",
      "node  (4, 9) has been popped from frontier with priority 13.0\n",
      "successor_nodes [(4, 8)]\n",
      "s: (4, 8) new distance: 12  old distance: inf\n",
      "Node (4, 8) has been pushed to frontier with priority 14.23606797749979\n",
      "step  33 . frontier:  [(13.0, (6, 6)), (13.602325267042627, (1, 2)), (13.385164807134505, (1, 7)), (14.099019513592784, (1, 8)), (13.94427190999916, (2, 1)), (15.0, (1, 9)), (14.23606797749979, (4, 8))]\n",
      "node  (6, 6) has been popped from frontier with priority 13.0\n",
      "successor_nodes [(5, 6)]\n",
      "s: (5, 6) new distance: 11  old distance: inf\n",
      "Node (5, 6) has been pushed to frontier with priority 14.16227766016838\n",
      "step  34 . frontier:  [(13.385164807134505, (1, 7)), (13.602325267042627, (1, 2)), (14.16227766016838, (5, 6)), (14.099019513592784, (1, 8)), (13.94427190999916, (2, 1)), (15.0, (1, 9)), (14.23606797749979, (4, 8))]\n",
      "node  (1, 7) has been popped from frontier with priority 13.385164807134505\n",
      "successor_nodes [(1, 8)]\n",
      "s: (1, 8) new distance: 9  old distance: 9\n",
      "step  35 . frontier:  [(13.602325267042627, (1, 2)), (13.94427190999916, (2, 1)), (14.16227766016838, (5, 6)), (14.099019513592784, (1, 8)), (14.23606797749979, (4, 8)), (15.0, (1, 9))]\n",
      "node  (1, 2) has been popped from frontier with priority 13.602325267042627\n",
      "successor_nodes [(1, 1)]\n",
      "s: (1, 1) new distance: 6  old distance: inf\n",
      "Node (1, 1) has been pushed to frontier with priority 15.433981132056603\n",
      "step  36 . frontier:  [(13.94427190999916, (2, 1)), (14.099019513592784, (1, 8)), (14.16227766016838, (5, 6)), (15.0, (1, 9)), (14.23606797749979, (4, 8)), (15.433981132056603, (1, 1))]\n",
      "node  (2, 1) has been popped from frontier with priority 13.94427190999916\n",
      "successor_nodes [(1, 1)]\n",
      "s: (1, 1) new distance: 6  old distance: 6\n",
      "step  37 . frontier:  [(14.099019513592784, (1, 8)), (14.23606797749979, (4, 8)), (14.16227766016838, (5, 6)), (15.0, (1, 9)), (15.433981132056603, (1, 1))]\n",
      "node  (1, 8) has been popped from frontier with priority 14.099019513592784\n",
      "successor_nodes [(1, 9)]\n",
      "s: (1, 9) new distance: 10  old distance: 10\n",
      "step  38 . frontier:  [(14.16227766016838, (5, 6)), (14.23606797749979, (4, 8)), (15.433981132056603, (1, 1)), (15.0, (1, 9))]\n",
      "node  (5, 6) has been popped from frontier with priority 14.16227766016838\n",
      "successor_nodes [(4, 6)]\n",
      "s: (4, 6) new distance: 12  old distance: inf\n",
      "Node (4, 6) has been pushed to frontier with priority 15.60555127546399\n",
      "step  39 . frontier:  [(14.23606797749979, (4, 8)), (15.0, (1, 9)), (15.433981132056603, (1, 1)), (15.60555127546399, (4, 6))]\n",
      "node  (4, 8) has been popped from frontier with priority 14.23606797749979\n",
      "successor_nodes [(4, 7), (5, 8)]\n",
      "s: (4, 7) new distance: 13  old distance: inf\n",
      "Node (4, 7) has been pushed to frontier with priority 15.82842712474619\n",
      "s: (5, 8) new distance: 13  old distance: inf\n",
      "Node (5, 8) has been pushed to frontier with priority 14.414213562373096\n",
      "step  40 . frontier:  [(14.414213562373096, (5, 8)), (15.0, (1, 9)), (15.433981132056603, (1, 1)), (15.82842712474619, (4, 7)), (15.60555127546399, (4, 6))]\n",
      "node  (5, 8) has been popped from frontier with priority 14.414213562373096\n",
      "successor_nodes [(6, 8)]\n",
      "s: (6, 8) new distance: 14  old distance: inf\n",
      "Node (6, 8) has been pushed to frontier with priority 15.0\n",
      "step  41 . frontier:  [(15.0, (1, 9)), (15.0, (6, 8)), (15.433981132056603, (1, 1)), (15.82842712474619, (4, 7)), (15.60555127546399, (4, 6))]\n",
      "node  (1, 9) has been popped from frontier with priority 15.0\n",
      "successor_nodes []\n",
      "step  42 . frontier:  [(15.0, (6, 8)), (15.60555127546399, (4, 6)), (15.433981132056603, (1, 1)), (15.82842712474619, (4, 7))]\n",
      "node  (6, 8) has been popped from frontier with priority 15.0\n",
      "successor_nodes [(7, 8), (6, 9)]\n",
      "s: (7, 8) new distance: 15  old distance: inf\n",
      "Node (7, 8) has been pushed to frontier with priority 16.414213562373096\n",
      "s: (6, 9) new distance: 15  old distance: inf\n",
      "Node (6, 9) has been pushed to frontier with priority 15.0\n",
      "step  43 . frontier:  [(15.0, (6, 9)), (15.433981132056603, (1, 1)), (15.82842712474619, (4, 7)), (16.414213562373096, (7, 8)), (15.60555127546399, (4, 6))]\n",
      "node  (6, 9) has been popped from frontier with priority 15.0\n",
      "Optimal path found. Steps:  43\n",
      "Costs matrix:  [[6, 5, 4, 5, 6, 7, 8, 9, 10], [5, 4, 3, 4, 5, 6, 7, 8, 9], [4, 3, 2, inf, inf, inf, inf, inf, 10], [3, 2, 1, 2, inf, 12, 13, 12, 11], [2, 1, 0, 1, inf, 11, inf, 13, inf], [3, inf, inf, inf, inf, 10, inf, 14, 15], [4, 5, 6, 7, 8, 9, inf, 15, inf]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astar_verbose(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the A* search returns the right values. The question is, how can we reconstruct the whole path?\n",
    "\n",
    "For this, we remove the `print` statements from the code for clarity and continue with the A* algorithm that we implemented in the previous step. Instead of returning the length of the shortest path, we have to return the path itself. We will write a function that extracts this path by walking backward from the end node, analyzing the `costs` matrix. Do not define this function globally yet. We define it as a local function in the A* algorithm that we created previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path(end_node):\n",
    "    path = [end_node]\n",
    "    distance = get_distance_from_start(end_node)\n",
    "    \n",
    "    while distance > 0:\n",
    "        for neighbor in successors(path[-1], []):\n",
    "            new_distance = get_distance_from_start(neighbor)\n",
    "            if new_distance < distance:\n",
    "                path += [neighbor]\n",
    "                distance = new_distance\n",
    "                break  # for\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to deconstruct the path, let's return it inside the A* algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_with_path(start, end):\n",
    "    frontier = []\n",
    "    internal = set()\n",
    "    heapq.heappush(frontier, (0, start))\n",
    "    costs = initialize_costs(size, start)\n",
    "    \n",
    "    def get_distance_from_start(node):\n",
    "        return costs[node[0] - 1][node[1] - 1]\n",
    "    \n",
    "    def set_distance_from_start(node, new_distance):\n",
    "        costs[node[0] - 1][node[1] -1] = new_distance\n",
    "        \n",
    "    def get_shortest_path(end_node):\n",
    "        path = [end_node]\n",
    "        distance = get_distance_from_start(end_node)\n",
    "        \n",
    "        while distance > 0:\n",
    "            for neighbor in successors(path[-1], []):\n",
    "                new_distance = get_distance_from_start(neighbor)\n",
    "                if new_distance < distance:\n",
    "                    path += [neighbor]\n",
    "                    distance = new_distance\n",
    "                    break  # for\n",
    "        return path\n",
    "        \n",
    "    while len(frontier) > 0:\n",
    "        (priority, node) = heapq.heappop(frontier)\n",
    "        \n",
    "        if node == end:\n",
    "            return get_shortest_path(end)\n",
    "        \n",
    "        internal.add(node)\n",
    "        successor_nodes = successors(node, internal)\n",
    "        \n",
    "        for s in successor_nodes:\n",
    "            new_distance = get_distance_from_start(node) + 1\n",
    "            if new_distance < get_distance_from_start(s):\n",
    "                set_distance_from_start(s, new_distance)\n",
    "                # filter previous entries of s\n",
    "                frontier = [n for n in frontier if s != n[1]]\n",
    "                new_priority = new_distance + distance_heuristic(s, end)\n",
    "                heapq.heappush(frontier, (new_priority, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 9),\n",
       " (6, 8),\n",
       " (5, 8),\n",
       " (4, 8),\n",
       " (4, 9),\n",
       " (3, 9),\n",
       " (2, 9),\n",
       " (2, 8),\n",
       " (2, 7),\n",
       " (2, 6),\n",
       " (2, 5),\n",
       " (2, 4),\n",
       " (2, 3),\n",
       " (3, 3),\n",
       " (4, 3),\n",
       " (5, 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astar_with_path(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, we do not need to reconstruct the path from the costs matrix. We could record the parent node of each node in the matrix and simply retrieve the coordinates to save a bit of searching.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* Search in Practice Using the simpleai Library\n",
    "\n",
    "The simpleai library is available on GitHub and contains many popular AI tools and techniques.\n",
    "\n",
    "  > **Note**  \n",
    "  > You can access this library at [https://github.com/simpleai-team/simpleai](https://github.com/simpleai-team/simpleai). The documentation of the `simpleai` library can be accessed [here](http://simpleai.readthedocs.io/en/latest/). To access the `simpleai` library, first, you have to install it.\n",
    "  \n",
    "The `simpleai` library can be installed as follows:\n",
    "\n",
    "```Bash\n",
    "pip install simpleai\n",
    "```\n",
    "\n",
    "Once `simpleai` has been installed, you can import classes and functions from the `simpleai` library into a Jupyter Notebook:\n",
    "\n",
    "```Python\n",
    "from simpleai.search import SearchProblem, astar\n",
    "```\n",
    "\n",
    "`SearchProblem` gives you a frame for defining any search problems. The `astar` import is responsible for executing the A* algorithm inside the search problem.\n",
    "\n",
    "For simplicity, we have not used classes in the previous code examples to focus on the algorithms in a plain old style without any clutter.\n",
    "\n",
    "  > **Note** \n",
    "  > Remember that the simpleai library will force us to use classes.\n",
    "  \n",
    "To describe a search problem, you need to provide the following:\n",
    "\n",
    "  * `constructor`: This initializes the state space, thus describing the problem. We will make the `Size`, `Start`, `End`, and `Obstacles` values available in the object by adding it to these as properties. At the end of the constructor, do not forget to call the super constructor, and do not forget to supply the initial state.\n",
    "  * `actions( state )`: This returns a list of actions that we can perform from a given state. We will use this function to generate new states. Semantically, it would make more sense to create action constants such as UP, DOWN, LEFT, and RIGHT, and then interpret these action constants as a result. However, in this implementation, we will simply interpret an action as \"move to $(x, y)$\", and represent this command as $(x, y)$. This function contains more-or-less the logic that we implemented in the succ function previously, except that we won't filter the result based on a set of visited nodes.\n",
    "  * `result( state0, action)`: This returns the new state of action that was applied to `state0`.\n",
    "  * `is_goal( state )`: This returns `True` if the state is a goal state. In our implementation, we will have to compare the state to the end state coordinates.\n",
    "  * `cost( self, state, action, newState )`: This is the cost of moving from `state` to `newState` via `action`. In our example, the cost of a move is uniformly 1.\n",
    "  \n",
    "  \n",
    "Have a look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from simpleai.search import SearchProblem, astar\n",
    "\n",
    "class ShortestPath(SearchProblem):\n",
    "    def __init__(self, size, start, end, obstacles):\n",
    "        super(ShortestPath, self).__init__(initial_state=start)\n",
    "        self.size = size\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.obstacles = obstacles\n",
    "        \n",
    "    def actions(self, state):\n",
    "        (row, col) = state\n",
    "        (max_row, max_col) = self.size\n",
    "        succ_states = []\n",
    "        if row > 1:\n",
    "            succ_states += [(row-1, col)]\n",
    "        if col > 1:\n",
    "            succ_states += [(row, col-1)]\n",
    "        if row < max_row:\n",
    "            succ_states += [(row+1, col)]\n",
    "        if row < max_col:\n",
    "            succ_states += [(row, col+1)]\n",
    "            return [s for s in succ_states if s not in self.obstacles]\n",
    "        \n",
    "    def result(self, state, action):\n",
    "        return action\n",
    "    \n",
    "    def is_goal(self, state):\n",
    "        return state == end\n",
    "    \n",
    "    def cost(self, state, action, new_state):\n",
    "        return 1\n",
    "    \n",
    "    def heuristic(self, state):\n",
    "        (x, y) = state\n",
    "        (u, v) = self.end\n",
    "        return math.sqrt(abs(x-u) ** 2 + abs(y-v) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, (5, 3)),\n",
       " ((4, 3), (4, 3)),\n",
       " ((3, 3), (3, 3)),\n",
       " ((2, 3), (2, 3)),\n",
       " ((2, 4), (2, 4)),\n",
       " ((2, 5), (2, 5)),\n",
       " ((2, 6), (2, 6)),\n",
       " ((2, 7), (2, 7)),\n",
       " ((2, 8), (2, 8)),\n",
       " ((2, 9), (2, 9)),\n",
       " ((3, 9), (3, 9)),\n",
       " ((4, 9), (4, 9)),\n",
       " ((4, 10), (4, 10)),\n",
       " ((5, 10), (5, 10)),\n",
       " ((6, 10), (6, 10)),\n",
       " ((6, 9), (6, 9))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchProblem = ShortestPath(size, start, end, obstacles)\n",
    "result = astar(searchProblem, graph_search=True)\n",
    "result.path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code snippet, we used the `simpleai` package to simplify our code. We also had to define a class called `ShortestPath` in order to use the package.\n",
    "\n",
    "The `simpleai` library made the search description a lot easier than the manual implementation. All we need to do is define a few basic methods, and then we have access to an effective search implementation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game AI with the Minmax Algorithm and Alpha-Beta Pruning\n",
    "\n",
    "In the first two sections, we saw how hard it was to create a winning strategy for a simple game such as tic-tac-toe. The previous section introduced a few structures for solving search problems with the A* algorithm. We also saw that tools such as the `simpleai` library help us to reduce the effort we put in to describe a task with code.\n",
    "\n",
    "We will use all of this knowledge to supercharge our game AI skills and solve more complex problems.\n",
    "\n",
    "## Search Algorithms for Turn-Based Multiplayer Games\n",
    "\n",
    "Turn-based multiplayer games such as tic-tac-toe are similar to pathfinding problems. We have an initial state and we have a set of end states where we win the game.\n",
    "\n",
    "The challenge with turn-based multiplayer games is the combinatorial explosion of the opponent's possible moves. This difference justifies treating turn-based games differently to a regular pathfinding problem.\n",
    "\n",
    "For instance, in the tic-tac-toe game, from an empty board, we can select one of the nine cells and place our sign there, assuming we start the game. Let's denote this algorithm with the `succ` function, symbolizing the creation of successor states. Consider we have the initial state denoted by $Si$.\n",
    "\n",
    "Here, we have `succ(Si)` returns `[ S1, S2, ..., Sn ]`, where `S1, S2, ..., Sn` are successor states:\n",
    "\n",
    "![Figure 1.20](img/fig1_20.jpg)\n",
    "\n",
    "Then, the opponent also makes a move, meaning that from each possible state, we have to examine even more states:\n",
    "\n",
    "![Figure 1.21](img/fig1_21.jpg)\n",
    "\n",
    "The expansion of possible future states stops in one of two cases:\n",
    "\n",
    "  * The game ends.\n",
    "  * Due to resource limitations, it is not worth explaining any more moves beyond a certain depth for the state of a certain utility.\n",
    "  \n",
    "e. This is exactly what we did previously with the A* algorithm, when choosing the best move; however, we never considered future states.\n",
    "\n",
    "Therefore, even though our algorithm became more and more complex, without using the knowledge of possible future states, we had a hard time detecting whether our current move would likely be a winning one or a losing one.\n",
    "\n",
    "The only way for us to take control of the future was to change our heuristic while knowing how many games we would win, lose, or tie in the future. We could either maximize our wins or minimize our losses. We still did not dig deep enough to see whether our losses could have been avoided through smarter play on the part of the AI.\n",
    "\n",
    "All these problems can be avoided by digging deeper into future states and recursively evaluating the utility of the branches.\n",
    "\n",
    "To consider future states, we will learn about the **Minmax** algorithm and its variant, the **NegaMax** algorithm.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Minmax Algorithm\n",
    "\n",
    "uppose there is a game where a heuristic function can evaluate a game state from the perspective of the AI player. For instance, we used a specific evaluation for the tic-tac-toe exercise:\n",
    "\n",
    "  * $+1,000$ points for a move that won the game\n",
    "  * $+100$ points for a move preventing the opponent from winning the game\n",
    "  * $+10$ points for a move creating two in a row, column, or diagonal\n",
    "  * $+1$ point for a move creating one in a row, column, or diagonal\n",
    "  \n",
    "This static evaluation is straightforward to implement on any node. The problem is that as we go deep into the tree of all possible future states, we do not yet know what to do with these scores. This is where the Minmax algorithm comes into play.\n",
    "\n",
    "Suppose we construct a tree with each possible move that could be performed by each player up to a certain depth. At the bottom of the tree, we evaluate each option. For the sake of simplicity, let's assume that we have a search tree that appears as follows:\n",
    "\n",
    "![Figure 1.22](img/fig1_22.jpg)\n",
    "\n",
    "The AI plays with $X$, and the player plays with $O$. A node with $X$ means that it is $X$'s turn to move. A node with $O$ means it is $O$'s turn to act.\n",
    "\n",
    "Suppose there are all $O$ leaves at the bottom of the tree, and we didn't compute any more values because of resource limitations. Our task is to evaluate the utility of the leaves:\n",
    "\n",
    "![Figure 1.23](img/fig1_23.jpg)\n",
    "\n",
    "We have to select the best possible move from our perspective because our goal is to maximize the utility of our move. This aspiration to maximize our gains represents the Max part in the Minmax algorithm:\n",
    "\n",
    "![Figure 1.24](img/fig1_24.jpg)\n",
    "\n",
    "If we move one level higher, it is our opponent's turn to act. Our opponent picks the value that is the least beneficial to us. This is because our opponent's job is to minimize our chances of winning the game. This is the Min part of the Minmax algorithm:\n",
    "\n",
    "![Figure 1.25](img/fig1_25.jpg)\n",
    "\n",
    "At the top, we can choose between a move with utility $101$ and another move with utility $21$. Since we are maximizing our value, we should pick $101$:\n",
    "\n",
    "![Figure 1.26](img/fig1_26.jpg)\n",
    "\n",
    "Let's see how we can implement this idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(state, depth, is_maximizing):\n",
    "    if depth == 0 or is_end_state(state):\n",
    "        return utility(state)\n",
    "    if is_maximizing:\n",
    "        utility = 0\n",
    "        for s in successors(state):\n",
    "            score = MinMax(s, depth - 1, false)\n",
    "            utility = max(utility, score)\n",
    "        return utility\n",
    "    else:\n",
    "        utility = infinity\n",
    "        for s in successors(state):\n",
    "            score = MinMax(s, depth - 1, true)\n",
    "            utility = min(utility, score)\n",
    "        return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his is the Minmax algorithm. We evaluate the leaves from our perspective. Then, from the bottom up, we apply a recursive definition:\n",
    "\n",
    "  * Our opponent plays optimally by selecting the worst possible node from our perspective.\n",
    "  * We play optimally by selecting the best possible node from our perspective.\n",
    "  \n",
    "We need a few more things in order to understand the application of the Minmax algorithm on the tic-tac-toe game:\n",
    "\n",
    "  * `is_end_state` is a function that determines whether the state should be evaluated instead of digging deeper, either because the game has ended, or because the game is about to end using forced moves. Using our utility function, it is safe to say that as soon as we reach a score of 1,000 or higher, we have effectively won the game. Therefore, `is_end_state` can simply check the score of a node and determine whether we need to dig deeper.\n",
    "  * Although the `successors` function only depends on the state, it is practical to pass the information of whose turn it is to make a move. Therefore, do not hesitate to add an argument if needed; you do not have to follow the pseudo code.\n",
    "  * We want to minimize our efforts in implementing the Minmax algorithm. For this reason, we will evaluate existing implementations of the algorithm. We will also simplify the duality of the description of the algorithm in the remainder of this section.\n",
    "  * The suggested utility function is quite accurate compared to the utility functions that we could be using in this algorithm. In general, the deeper we go, the less accurate our utility function has to be. For instance, if we could go nine steps deep into the tic-tac-toe game, all we would need to do is award 1 point for a win, 0 for a draw, and -1 point for a loss, given that, in nine steps, the board is complete, and we have all of the necessary information to make the evaluation. If we could only look four steps deep, this utility function would be completely useless at the start of the game because we need at least five steps to win the game.\n",
    "  * The Minmax algorithm could be optimized further by pruning the tree. Pruning is an act where we get rid of branches that do not contribute to the result. By eliminating unnecessary computations, we save precious resources that could be used to go deeper into the tree.\n",
    "  \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Minmax Algorithm with Alpha-Beta Pruning\n",
    "\n",
    "The last consideration in the previous thought process primed us to explore possible optimizations by reducing the search space by focusing our attention on nodes that matter.\n",
    "\n",
    "There are a few constellations of nodes in the tree where we can be sure that the evaluation of a subtree does not contribute to the end result. We will find, examine, and generalize these constellations to optimize the Minmax algorithm.\n",
    "\n",
    "Let's examine pruning through the previous example of nodes:\n",
    "\n",
    "![Figure 1.27](img/fig1_27.jpg)\n",
    "\n",
    "After computing the nodes with values $101$, $23$, and $110$, we can conclude that two levels above, the value $101$ will be chosen. Why?\n",
    "\n",
    "  * Suppose $X <= 110$. Here, the maximum of $110$ and $X$ will be chosen, which is $110$, and $X$ will be omitted.\n",
    "  * Suppose $X > 110$. Here, the maximum of $110$ and $X$ is $X$. One level above, the algorithm will choose the lowest value out of the two. The minimum of $101$ and $X$ will always be $101$, because $X > 110$. Therefore, $X$ will be omitted a level above.\n",
    "  \n",
    "This is how we prune the tree.\n",
    "\n",
    "On the right-hand side, suppose we computed branches $10$ and $21$. Their maximum is $21$. The implication of computing these values is that we can omit the computation of nodes Y1, Y2, and Y3, and we know that the value of Y4 is less than or equal to $21$. Why?\n",
    "\n",
    "The minimum of $21$ and Y3 is never greater than 21. Therefore, Y4 will never be greater than $21$.\n",
    "\n",
    "We can now choose between a node with utility $101$ and another node with a maximal utility of $21$. It is obvious that we have to choose the node with utility $101$:\n",
    "\n",
    "![Figure 1.28](img/fig1_28.jpg)\n",
    "\n",
    "This is the idea behind alpha-beta pruning. We prune subtrees that we know are not going to be needed.\n",
    "\n",
    "Let's see how we can implement alpha-beta pruning in the Minmax algorithm.\n",
    "\n",
    "First, we will add an alpha and a beta argument to the argument list of Minmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(state, depth, is_maximizing, alpha, beta):\n",
    "    if depth == 0 or is_end_state(state):\n",
    "        return utility(state)\n",
    "    if is_maximizing:\n",
    "        utility = 0\n",
    "        for s in successors(state):\n",
    "            score = MinMax(s, depth -1, false, alpha, beta)\n",
    "            utility = max(utility, score)\n",
    "            alpha = max(alpha, score)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return utility\n",
    "    else:\n",
    "        utility = infinity\n",
    "        for s in successors(state):\n",
    "            score = MinMax(s, depth -1, true, alpha, beta)\n",
    "            utility = min(utility, score)\n",
    "        return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code snippet, we added the `alpha` and `beta` arguments to the `MinMax` function in order to calculate the new alpha score as being the maximum between `alpha` and `beta` in the maximizing branch.\n",
    "\n",
    "Now, we need to do the same with the minimizing branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(state, depth, is_maximizing, alpha, beta):\n",
    "    if depth == 0 or is_end_state(state):\n",
    "        return utility(state)\n",
    "    \n",
    "    if is_maximizing:\n",
    "        utility = 0\n",
    "        for s in successors(state):\n",
    "            score = min_max(s, depth - 1, false, alpha, beta)\n",
    "            utility = max(utility, score)\n",
    "            alpha = max(utility, score)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "            return utility\n",
    "    else:\n",
    "        utility = infinity\n",
    "        for s in successors(state):\n",
    "            score = min_max(s, depth -1, true, alpha, beta)\n",
    "            utility = min(utility, score)\n",
    "            beta = min(beta, score)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code snippet, we added the new beta score in the `else` branch, which is the minimum between `alpha` and `beta` in the minimizing branch.\n",
    "\n",
    "We are done with the implementation. It is recommended that you mentally execute the algorithm on our example tree step by step to get a feel for the implementation.\n",
    "\n",
    "One important piece is missing that has prevented us from doing the execution properly: the initial values for `alpha` and `beta`. Any number that is outside the possible range of utility values will do. We will use positive and negative infinity as initial values to call the Minmax algorithm:\n",
    "\n",
    "```Python\n",
    "alpha = infinity\n",
    "beta = -infinity\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRYing Up the Minmax Algorithm – the NegaMax Algorithm\n",
    "\n",
    "The Minmax algorithm works great, especially with alpha-beta pruning. The only problem is that we have `if` and `else` branches in the algorithm that essentially negates each other.\n",
    "\n",
    "As we know, in computer science, there is *DRY* code and *WET* code. **DRY** stands for **Don't Repeat Yourself**. **WET** stands for **Write Everything Twice**. When we write the same code twice, we double our chance of making a mistake while writing it. We also double our chances of each maintenance effort being executed in the future. Hence, it is better to reuse our code.\n",
    "\n",
    "When implementing the Minmax algorithm, we always compute the utility of a node from the perspective of the AI player. This is why we have to have a utility-maximizing branch and a utility-minimizing branch in the implementations that are dual in nature. As we prefer clean code that describes the problem only once, we could get rid of this duality by changing the point of view of the evaluation.\n",
    "\n",
    "Whenever the AI player's turn comes, nothing changes in the algorithm.\n",
    "\n",
    "Whenever the opponent's turn comes, we negate the perspective. Minimizing the AI player's utility is equivalent to maximizing the opponent's utility.\n",
    "\n",
    "This simplifies the Minmax algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negamax(state, depth, is_player_point_of_view):\n",
    "    if depth == 0 or is_end_state(state):\n",
    "        return utility(state, is_player_point_if_view)\n",
    "    utility = 0\n",
    "    for s in successors(state):\n",
    "        score = Negamax(s, depth-1, not is_player_point_of_view)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are necessary conditions for using the NegaMax algorithm; for instance, the evaluation of the board state has to be symmetric. If a game state is worth +20 from the first player's perspective, it is worth -20 from the second player's perspective. Therefore, we often normalize the scores around zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the EasyAI Library\n",
    "\n",
    "We have already looked at the `simpleai` library, which helped us execute searches on pathfinding problems. Now, we will use the `EasyAI` library, which can easily handle an AI search on two-player games, reducing the implementation of the tic-tac-toe problem to writing a few functions on scoring the utility of a board and determining when the game ends.\n",
    "\n",
    "  > **Note**  \n",
    "  > You can read the documentation of the library on GitHub at [https://github.com/Zulko/easyAI](https://github.com/Zulko/easyAI).\n",
    "  \n",
    "**Go to Activity 1.04**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
